import json
import logging
import time
import asyncio
import uuid
from aiohttp import web
import aiohttp
import argparse
from typing import Dict, Any, Optional
import traceback


from utils import format_to_sharegpt, init_async_logger, get_async_logger, init_db_path, get_db_connection, save_conversation_async
import re
from aiohttp.web_middlewares import middleware



import os

# è‡ªå®šä¹‰æ—¥å¿—è¿‡æ»¤å™¨ï¼Œå±è”½æ¢é’ˆè¯·æ±‚çš„æ—¥å¿—
class ProbeRequestFilter(logging.Filter):
    """è¿‡æ»¤æ¢é’ˆè¯·æ±‚çš„æ—¥å¿—è®°å½•"""
    
    def __init__(self, config_file: str = None):
        super().__init__()
        
        # é»˜è®¤æ¢é’ˆè¯·æ±‚çš„ç‰¹å¾æ¨¡å¼
        default_patterns = []
        
        # é»˜è®¤æ¢é’ˆIPåœ°å€æ¨¡å¼ï¼ˆä½¿ç”¨æ›´é€šç”¨çš„æ¨¡å¼ï¼‰
        default_probe_ips = []
        
        # å°è¯•ä»é…ç½®æ–‡ä»¶åŠ è½½è‡ªå®šä¹‰æ¨¡å¼
        self.probe_patterns = default_patterns.copy()
        self.probe_ip_patterns = default_probe_ips.copy()
        
        if config_file:
            self._load_config(config_file)
        
        # ç¼–è¯‘æ­£åˆ™è¡¨è¾¾å¼ä»¥æé«˜æ€§èƒ½
        all_patterns = self.probe_patterns + self.probe_ip_patterns
        self.compiled_patterns = [re.compile(pattern) for pattern in all_patterns]
    
    def _load_config(self, config_file: str):
        """ä»é…ç½®æ–‡ä»¶åŠ è½½è‡ªå®šä¹‰è¿‡æ»¤æ¨¡å¼"""
        try:
            import json
            import os
            if os.path.exists(config_file):
                with open(config_file, 'r', encoding='utf-8') as f:
                    config = json.load(f)
                    
                # åŠ è½½è‡ªå®šä¹‰æ¢é’ˆæ¨¡å¼
                if 'probe_filter' in config:
                    filter_config = config['probe_filter']
                    
                    # ç›´æ¥æ›¿æ¢ï¼šè‹¥æä¾› patterns / ip_patternsï¼Œåˆ™è¦†ç›–é»˜è®¤
                    if 'patterns' in filter_config and isinstance(filter_config['patterns'], list):
                        self.probe_patterns = filter_config['patterns']
                    if 'ip_patterns' in filter_config and isinstance(filter_config['ip_patterns'], list):
                        self.probe_ip_patterns = filter_config['ip_patterns']
                    
                    # å…¼å®¹ï¼šè¿½åŠ è‡ªå®šä¹‰æ¨¡å¼
                    if 'custom_patterns' in filter_config:
                        self.probe_patterns.extend(filter_config['custom_patterns'])
                    
                    # å…¼å®¹ï¼šè¿½åŠ è‡ªå®šä¹‰IPæ¨¡å¼
                    if 'custom_ip_patterns' in filter_config:
                        self.probe_ip_patterns.extend(filter_config['custom_ip_patterns'])
                    
                    # å…¼å®¹ï¼šé€šè¿‡disable_*æ¸…ç©ºé»˜è®¤å¹¶é‡‡ç”¨custom_*
                    if filter_config.get('disable_default_patterns', False):
                        self.probe_patterns = filter_config.get('custom_patterns', [])
                    
                    if filter_config.get('disable_default_ip_patterns', False):
                        self.probe_ip_patterns = filter_config.get('custom_ip_patterns', [])
                        
        except Exception as e:
            # é…ç½®æ–‡ä»¶åŠ è½½å¤±è´¥æ—¶ä½¿ç”¨é»˜è®¤é…ç½®
            print(f"è­¦å‘Š: æ— æ³•åŠ è½½æ¢é’ˆè¿‡æ»¤å™¨é…ç½®æ–‡ä»¶ {config_file}: {e}")
    
    def add_pattern(self, pattern: str):
        """åŠ¨æ€æ·»åŠ è¿‡æ»¤æ¨¡å¼"""
        try:
            compiled_pattern = re.compile(pattern)
            self.compiled_patterns.append(compiled_pattern)
            self.probe_patterns.append(pattern)
        except re.error as e:
            print(f"è­¦å‘Š: æ— æ•ˆçš„æ­£åˆ™è¡¨è¾¾å¼æ¨¡å¼ '{pattern}': {e}")
    
    def remove_pattern(self, pattern: str):
        """åŠ¨æ€ç§»é™¤è¿‡æ»¤æ¨¡å¼"""
        if pattern in self.probe_patterns:
            self.probe_patterns.remove(pattern)
            # é‡æ–°ç¼–è¯‘æ‰€æœ‰æ¨¡å¼
            all_patterns = self.probe_patterns + self.probe_ip_patterns
            self.compiled_patterns = [re.compile(p) for p in all_patterns]
    
    def filter(self, record):
        """è¿‡æ»¤æ—¥å¿—è®°å½•"""
        message = record.getMessage()
        
        # æ£€æŸ¥æ˜¯å¦åŒ¹é…ä»»ä½•æ¢é’ˆæ¨¡å¼
        for pattern in self.compiled_patterns:
            if pattern.search(message):
                return False  # è¿‡æ»¤æ‰è¿™æ¡æ—¥å¿—
        
        return True  # ä¿ç•™è¿™æ¡æ—¥å¿—

def parse_args():
    parser = argparse.ArgumentParser(description="åŠ¨æ€ä»£ç†ç«¯ç‚¹æœåŠ¡å™¨")
    parser.add_argument("--port", type=int, default=8080, help="æœåŠ¡å™¨ç«¯å£")
    parser.add_argument("--log-level", default="INFO", choices=["DEBUG", "INFO", "WARNING", "ERROR"], help="æ—¥å¿—çº§åˆ«")
    return parser.parse_args()

args = parse_args()

# é…ç½®æ—¥å¿—
logging.basicConfig(level=getattr(logging, args.log_level.upper()))
logger = logging.getLogger(__name__)

# æ¸…é™¤ç°æœ‰çš„å¤„ç†å™¨
for handler in logger.handlers[:]:
    logger.removeHandler(handler)

# åˆ›å»ºæ¢é’ˆè¿‡æ»¤å™¨
# åˆ›å»ºæ¢é’ˆè¿‡æ»¤å™¨å®ä¾‹ï¼Œå°è¯•åŠ è½½é…ç½®æ–‡ä»¶
probe_filter = ProbeRequestFilter("config.json")

# ä¸ºç›¸å…³çš„æ—¥å¿—å™¨æ·»åŠ è¿‡æ»¤å™¨
aiohttp_access_logger = logging.getLogger('aiohttp.access')
aiohttp_server_logger = logging.getLogger('aiohttp.server')
asyncio_logger = logging.getLogger('asyncio')

# ä¸ºæ¯ä¸ªæ—¥å¿—å™¨æ·»åŠ è¿‡æ»¤å™¨
for log in [aiohttp_access_logger, aiohttp_server_logger, asyncio_logger]:
    log.addFilter(probe_filter)
    # ä¹Ÿä¸ºç°æœ‰çš„å¤„ç†å™¨æ·»åŠ è¿‡æ»¤å™¨
    for handler in log.handlers:
        handler.addFilter(probe_filter)

# å…¨å±€å¼‚æ­¥å¼‚å¸¸å¤„ç†å™¨
def handle_asyncio_exception(loop, context):
    """å¤„ç†asyncioä¸­æœªæ•è·çš„å¼‚å¸¸"""
    exception = context.get('exception')
    if exception:
        # æ£€æŸ¥æ˜¯å¦æ˜¯æ¢é’ˆç›¸å…³çš„å¼‚å¸¸
        error_message = str(exception)
        probe_filter_instance = ProbeRequestFilter()
        
        # åˆ›å»ºä¸€ä¸ªæ¨¡æ‹Ÿçš„æ—¥å¿—è®°å½•æ¥æµ‹è¯•è¿‡æ»¤å™¨
        class MockRecord:
            def getMessage(self):
                return error_message
        
        mock_record = MockRecord()
        if not probe_filter_instance.filter(mock_record):
            return  # å¦‚æœæ˜¯æ¢é’ˆç›¸å…³å¼‚å¸¸ï¼Œå¿½ç•¥å®ƒ
        
        logger.error(f"æœªæ•è·çš„asyncioå¼‚å¸¸: {exception}", exc_info=exception)
    else:
        logger.error(f"æœªæ•è·çš„asyncioé”™è¯¯: {context}")

@middleware
async def probe_request_middleware(request, handler):
    """ä¸­é—´ä»¶ï¼šè¿‡æ»¤æ¢é’ˆè¯·æ±‚"""
    # è·å–å®¢æˆ·ç«¯IP
    client_ip = request.remote
    if 'X-Forwarded-For' in request.headers:
        client_ip = request.headers['X-Forwarded-For'].split(',')[0].strip()
    elif 'X-Real-IP' in request.headers:
        client_ip = request.headers['X-Real-IP']
    
    # æ£€æŸ¥æ˜¯å¦ä¸ºæ¢é’ˆè¯·æ±‚
    user_agent = request.headers.get('User-Agent', '')
    path = request.path
    method = request.method
    
    # æ¢é’ˆè¯·æ±‚ç‰¹å¾ï¼ˆå¯é…ç½®ï¼‰
    cfg = request.app.get('config', {}) if hasattr(request, 'app') else {}
    probe_cfg = cfg.get('probe_request', {}) if isinstance(cfg, dict) else {}
    path_blocklist = probe_cfg.get('path_blocklist', ['/', '/favicon.ico'])
    path_prefix_blocklist = probe_cfg.get('path_prefix_blocklist', ['/.well-known/', '/locales/'])
    ua_blocklist = probe_cfg.get('user_agent_substrings', ['CensysInspect', 'Go-http-client'])
    methods_allowed = probe_cfg.get('allowed_methods', ['GET', 'POST', 'PUT', 'DELETE', 'PATCH', 'OPTIONS'])
    ip_blocklist = probe_cfg.get('ip_blocklist', ['193.34.212.110', '185.191.127.222', '162.142.125.124', '194.62.248.69', '209.38.219.203'])
    
    probe_indicators = [
        (path in path_blocklist) or any(path.startswith(p) for p in path_prefix_blocklist),
        any(s in user_agent for s in ua_blocklist),
        method not in methods_allowed,
        client_ip in ip_blocklist
    ]
    
    if any(probe_indicators):
        # é™é»˜è¿”å›404ï¼Œä¸è®°å½•æ—¥å¿—
        return web.Response(status=404, text="Not Found")
    
    # æ­£å¸¸è¯·æ±‚ï¼Œç»§ç»­å¤„ç†
    return await handler(request)

class DynamicProxyEndpoint:
    """åŠ¨æ€ä»£ç†ç«¯ç‚¹ï¼Œæ— éœ€é…ç½®æ–‡ä»¶"""
    
    def __init__(self, port: int = 8080):
        self.port = port
        self.app = web.Application(middlewares=[probe_request_middleware])
        self.setup_routes()
        
        # åŠ è½½é…ç½®æ–‡ä»¶ï¼ˆå¯é€‰ï¼‰
        self.config = {}
        try:
            if os.path.exists("config.json"):
                with open("config.json", "r", encoding="utf-8") as f:
                    self.config = json.load(f)
        except Exception:
            self.config = {}
        
        # æ€§èƒ½ä¼˜åŒ–ç›¸å…³
        self.http_session = None
        self.async_logger = None
        self.conversation_queue = None
        self.batch_size = 10
        self.batch_timeout = 5.0
        self.batch_save_task = None  # æ·»åŠ æ‰¹é‡ä¿å­˜ä»»åŠ¡çš„å¼•ç”¨
        
        # åŸŸåç™½åå•å’Œè®¤è¯æ˜ å°„
        # æœ€å°ç™½åå•ï¼ˆå®Œæ•´åˆ—è¡¨è¿ç§»è‡³ config.jsonï¼‰
        self.allowed_domains = {
            'generativelanguage.googleapis.com': {'auth_type': 'google', 'https': True},
            'api.openai.com': {'auth_type': 'openai', 'https': True}
        }
        
        # å…è®¸ç”¨é…ç½®è¦†ç›– allowed_domains
        try:
            cfg_domains = self.config.get("allowed_domains") if isinstance(self.config, dict) else None
            if isinstance(cfg_domains, dict):
                self.allowed_domains = cfg_domains
        except Exception:
            pass
        
        # è®¾ç½®åº”ç”¨å¯åŠ¨å’Œæ¸…ç†äº‹ä»¶
        self.app.on_startup.append(self.init_async_resources)
        self.app.on_cleanup.append(self.cleanup_resources)
    
    def setup_routes(self):
        """è®¾ç½®è·¯ç”±"""
        # æ ‡å‡†OpenAI APIç«¯ç‚¹è·¯ç”±ï¼ˆä¼˜å…ˆçº§æ›´é«˜ï¼‰
        self.app.router.add_post("/v1/chat/completions", self.handle_openai_api)
        self.app.router.add_post("/v1/completions", self.handle_openai_api)
        self.app.router.add_post("/v1/embeddings", self.handle_openai_api)
        
        # åŠ¨æ€ä»£ç†è·¯ç”±ï¼š/{domain}/{path:.*}
        self.app.router.add_post("/{domain}/{path:.*}", self.handle_dynamic_proxy)
        self.app.router.add_get("/health", self.handle_health_check)
        
    async def init_async_resources(self, app):
        """åˆå§‹åŒ–å¼‚æ­¥èµ„æº"""
        # è®¾ç½®å…¨å±€å¼‚æ­¥å¼‚å¸¸å¤„ç†å™¨
        loop = asyncio.get_event_loop()
        loop.set_exception_handler(handle_asyncio_exception)
        
        # åˆå§‹åŒ–å¼‚æ­¥æ—¥å¿—
        await asyncio.to_thread(init_async_logger, "proxy_dynamic", "proxy_dynamic.log", getattr(logging, args.log_level.upper()))
        self.async_logger = get_async_logger()
        if self.async_logger is None:
            raise ValueError("Failed to initialize async_logger")
        await self.async_logger.info("âœ… å¼‚æ­¥æ—¥å¿—åˆå§‹åŒ–å®Œæˆ")
        
        # å°†é…ç½®æ³¨å…¥appï¼Œä¾›ä¸­é—´ä»¶ç­‰ä½¿ç”¨
        self.app['config'] = getattr(self, 'config', {})
        
        # åˆå§‹åŒ–æ•°æ®åº“
        await init_db_path("interactions.db")
        await self.async_logger.info("âœ… æ•°æ®åº“åˆå§‹åŒ–å®Œæˆ")
        
        # åˆå§‹åŒ–HTTPè¿æ¥æ± 
        connector = aiohttp.TCPConnector(
            limit=100,
            limit_per_host=30,
            ttl_dns_cache=300,
            use_dns_cache=True,
            keepalive_timeout=30,
            enable_cleanup_closed=True
        )
        
        timeout = aiohttp.ClientTimeout(
            total=900,  # å¢åŠ æ€»è¶…æ—¶æ—¶é—´åˆ°15åˆ†é’Ÿ
            connect=60,  # å¢åŠ è¿æ¥è¶…æ—¶åˆ°60ç§’
            sock_connect=60,  # å¢åŠ socketè¿æ¥è¶…æ—¶åˆ°60ç§’
            sock_read=900  # å¢åŠ è¯»å–è¶…æ—¶åˆ°15åˆ†é’Ÿ
        )
        
        self.http_session = aiohttp.ClientSession(
            connector=connector,
            timeout=timeout,
            headers={'User-Agent': 'DynamicProxy/1.0'}
        )
        
        await self.async_logger.info("âœ… HTTPè¿æ¥æ± åˆå§‹åŒ–å®Œæˆ")
        
        # åˆå§‹åŒ–æ‰¹é‡å¤„ç†é˜Ÿåˆ—
        self.conversation_queue = asyncio.Queue(maxsize=1000)
        self.batch_save_task = asyncio.create_task(self._batch_save_conversations())
        await self.async_logger.info("âœ… æ‰¹é‡å¤„ç†é˜Ÿåˆ—åˆå§‹åŒ–å®Œæˆ")
        
        await self.async_logger.info("ğŸš€ åŠ¨æ€ä»£ç†æœåŠ¡å™¨å¯åŠ¨å®Œæˆ")
    
    async def cleanup_resources(self, app):
        """æ¸…ç†èµ„æº"""
        # åœæ­¢æ‰¹é‡ä¿å­˜ä»»åŠ¡å¹¶ç­‰å¾…å®Œæˆ
        if self.batch_save_task and not self.batch_save_task.done():
            self.batch_save_task.cancel()
            try:
                await self.batch_save_task
            except asyncio.CancelledError:
                pass
            
        # å¤„ç†é˜Ÿåˆ—ä¸­å‰©ä½™çš„å¯¹è¯æ•°æ®
        if self.conversation_queue and not self.conversation_queue.empty():
            remaining_conversations = []
            while not self.conversation_queue.empty():
                try:
                    conversation_data = self.conversation_queue.get_nowait()
                    remaining_conversations.append(conversation_data)
                except asyncio.QueueEmpty:
                    break
            
            # ä¿å­˜å‰©ä½™çš„å¯¹è¯æ•°æ®
            if remaining_conversations:
                await self._save_batch(remaining_conversations)
                if self.async_logger:
                    await self.async_logger.info(f"ğŸ’¾ ä¿å­˜äº† {len(remaining_conversations)} æ¡å‰©ä½™å¯¹è¯æ•°æ®")
        
        # å…³é—­HTTPä¼šè¯
        if self.http_session:
            await self.http_session.close()
            
        if self.async_logger:
            await self.async_logger.info("ğŸ”„ èµ„æºæ¸…ç†å®Œæˆ")
    
    def detect_auth_type_from_path(self, path: str) -> str:
        """æ ¹æ®è·¯å¾„æ¨¡å¼è¯†åˆ«è®¤è¯ç±»å‹"""
        # Google Gemini API è·¯å¾„æ¨¡å¼
        if "/v1beta/models/" in path and ":generateContent" in path:
            return "google"
        # Anthropic API è·¯å¾„æ¨¡å¼
        elif "/anthropic/" in path or "/v1/messages" in path:
            return "anthropic"
        # OpenAI API è·¯å¾„æ¨¡å¼
        elif "/v1/chat/completions" in path or "/chat/completions" in path:
            return "openai"
        elif "/v1/embeddings" in path:
            return "openai"
        elif "/v1/rerank" in path:
            return "openai"
        else:
            # é»˜è®¤ä½¿ç”¨openaiæ ¼å¼
            return "openai"
    
    def extract_model_from_request(self, request_data: Dict[str, Any], path: str, auth_type: str) -> str:
        """ä»è¯·æ±‚ä¸­æå–æ¨¡å‹åç§°"""
        # å¯¹äºGoogle Gemini APIï¼Œä»URLè·¯å¾„ä¸­æå–æ¨¡å‹åç§°
        if auth_type == "google" and "/v1beta/models/" in path:
            # è·¯å¾„æ ¼å¼: /v1beta/models/gemini-pro:generateContent
            # æˆ–: /v1beta/models/gemini-2.5-pro:streamGenerateContent
            import re
            match = re.search(r'/v1beta/models/([^:]+)', path)
            if match:
                return match.group(1)
        
        # å¯¹äºå…¶ä»–APIï¼Œä»è¯·æ±‚ä½“ä¸­è·å–æ¨¡å‹åç§°
        return request_data.get("model", "unknown")
    
    def prepare_auth_headers(self, request_headers: Dict[str, str], auth_type: str) -> Dict[str, str]:
        """æ ¹æ®è®¤è¯ç±»å‹å‡†å¤‡è¯·æ±‚å¤´"""
        base_headers = {"Content-Type": "application/json"}
        
        if auth_type == "anthropic":
            # Anthropicè®¤è¯å¤„ç†
            auth_header = request_headers.get("Authorization", "")
            api_key = ""
            if auth_header.startswith("Bearer "):
                api_key = auth_header.replace("Bearer ", "").strip()
            elif request_headers.get("x-api-key"):
                api_key = request_headers.get("x-api-key")
            
            base_headers["Authorization"] = f"Bearer {api_key}"
        elif auth_type == "google":
            # Google APIè®¤è¯å¤„ç†
            auth_header = request_headers.get("Authorization", "")
            if auth_header.startswith("Bearer "):
                base_headers["Authorization"] = auth_header
            else:
                # å¦‚æœæ²¡æœ‰Bearer tokenï¼Œå°è¯•ä»x-goog-api-keyè·å–
                api_key = request_headers.get("x-goog-api-key", "")
                if api_key:
                    base_headers["x-goog-api-key"] = api_key
                else:
                    base_headers["Authorization"] = auth_header
        else:
            # OpenAIåŠå…¶ä»–APIè®¤è¯å¤„ç†
            base_headers["Authorization"] = request_headers.get("Authorization", "")
        
        return base_headers
    
    def is_domain_allowed(self, domain: str) -> bool:
        """æ£€æŸ¥åŸŸåæ˜¯å¦åœ¨ç™½åå•ä¸­"""
        return domain in self.allowed_domains
    
    def get_target_url(self, domain: str, path: str) -> str:
        """æ„å»ºç›®æ ‡URL"""
        domain_config = self.allowed_domains.get(domain, {'https': True})
        protocol = 'https' if domain_config.get('https', True) else 'http'
        # ä¿ç•™åŸå§‹è·¯å¾„å’ŒæŸ¥è¯¢å‚æ•°
        return f"{protocol}://{domain}{path}"
    
    async def handle_openai_api(self, request: web.Request) -> web.StreamResponse:
        """å¤„ç†æ ‡å‡†OpenAI APIç«¯ç‚¹è¯·æ±‚"""
        try:
            # è·å–è¯·æ±‚æ•°æ®
            headers = dict(request.headers)
            request_data = await request.json()
            
            # è°ƒè¯•ï¼šæ‰“å°å®¢æˆ·ç«¯å‘é€çš„æ¶ˆæ¯
            await self.async_logger.info(f"ğŸ” OpenAI API - å®¢æˆ·ç«¯è¯·æ±‚æ•°æ®: {json.dumps(request_data, ensure_ascii=False, indent=2)}")
            
            # è¯·æ±‚ä½“å¤§å°æ£€æŸ¥
            if not await self._validate_request_size(request_data):
                return web.Response(
                    status=413,
                    text=json.dumps({"error": "è¯·æ±‚ä½“è¿‡å¤§ï¼Œè¯·å‡å°è¾“å…¥æ•°æ®å¤§å°æˆ–åˆ†æ‰¹å¤„ç†"})
                )
            
            # ä»è¯·æ±‚å¤´ä¸­è·å–Authorizationï¼Œç¡®å®šç›®æ ‡åŸŸå
            auth_header = headers.get('Authorization', '')
            if not auth_header.startswith('Bearer '):
                return web.Response(
                    status=401,
                    text=json.dumps({"error": "ç¼ºå°‘æœ‰æ•ˆçš„Authorizationå¤´"})
                )
            
            # æ ¹æ®API Keyæˆ–æ¨¡å‹åç§°ç¡®å®šç›®æ ‡åŸŸå
            # è¿™é‡Œä½¿ç”¨é»˜è®¤çš„Google Gemini APIé…ç½®
            target_domain = 'generativelanguage.googleapis.com'
            auth_type = 'google'
            
            # æ„å»ºç›®æ ‡URL
            path = str(request.url.path)
            if request.query_string:
                path += '?' + request.query_string
            
            # å¯¹äºGoogle APIï¼Œéœ€è¦è½¬æ¢è·¯å¾„æ ¼å¼
            if auth_type == 'google':
                model = request_data.get('model', 'gemini-2.0-flash-exp')
                path = f"/v1beta/models/{model}:generateContent"
                if request_data.get('stream', False):
                    path = f"/v1beta/models/{model}:streamGenerateContent"
            
            target_url = self.get_target_url(target_domain, path)
            
            # å‡†å¤‡è®¤è¯å¤´
            auth_headers = self.prepare_auth_headers(headers, auth_type)
            
            # è½¬æ¢è¯·æ±‚æ•°æ®æ ¼å¼
            if auth_type == 'google':
                # è½¬æ¢OpenAIæ ¼å¼åˆ°Googleæ ¼å¼
                google_request = self._convert_openai_to_google(request_data)
                request_data = google_request
            
            # å‘é€è¯·æ±‚åˆ°ç›®æ ‡API
            async with self.http_session.post(
                target_url,
                headers=auth_headers,
                json=request_data,
                timeout=aiohttp.ClientTimeout(total=120)
            ) as resp:
                
                # æ£€æŸ¥æ˜¯å¦ä¸ºæµå¼å“åº”
                is_stream = request_data.get('stream', False) or 'text/event-stream' in resp.headers.get('content-type', '')
                
                if is_stream:
                    return await self._handle_stream_response(resp, request, auth_type, 
                                                            request_data.get('model', 'unknown'), request_data)
                else:
                    return await self._handle_non_stream_response(resp, auth_type, 
                                                                request_data.get('model', 'unknown'), request_data)
                    
        except Exception as e:
            await self.async_logger.error(f"âŒ OpenAI APIå¤„ç†å¼‚å¸¸: {e}", exc_info=True)
            return web.Response(
                status=500,
                text=json.dumps({"error": f"æœåŠ¡å™¨å†…éƒ¨é”™è¯¯: {str(e)}"})
            )
    
    def _convert_openai_to_google(self, openai_request: Dict[str, Any]) -> Dict[str, Any]:
        """å°†OpenAIæ ¼å¼è¯·æ±‚è½¬æ¢ä¸ºGoogleæ ¼å¼"""
        messages = openai_request.get('messages', [])
        
        # è½¬æ¢æ¶ˆæ¯æ ¼å¼
        contents = []
        for msg in messages:
            role = msg.get('role', 'user')
            content = msg.get('content', '')
            
            if role == 'system':
                # Google APIä¸­systemæ¶ˆæ¯éœ€è¦ç‰¹æ®Šå¤„ç†
                contents.append({
                    "role": "user",
                    "parts": [{"text": f"System: {content}"}]
                })
            elif role == 'user':
                contents.append({
                    "role": "user", 
                    "parts": [{"text": content}]
                })
            elif role == 'assistant':
                contents.append({
                    "role": "model",
                    "parts": [{"text": content}]
                })
        
        # æ„å»ºGoogle APIè¯·æ±‚
        google_request = {
            "contents": contents,
            "generationConfig": {
                "temperature": openai_request.get('temperature', 0.7),
                "maxOutputTokens": openai_request.get('max_tokens', 2048),
                "topP": openai_request.get('top_p', 1.0),
            }
        }
        
        return google_request

    async def handle_dynamic_proxy(self, request: web.Request) -> web.StreamResponse:
        """å¤„ç†åŠ¨æ€ä»£ç†è¯·æ±‚"""
        try:
            # è§£æURLå‚æ•°
            domain = request.match_info['domain']
            path = '/' + request.match_info['path']
            
            # ä¿ç•™æŸ¥è¯¢å‚æ•°
            if request.query_string:
                path += '?' + request.query_string
            
            # å®‰å…¨æ£€æŸ¥ï¼šéªŒè¯åŸŸåç™½åå•
            if not self.is_domain_allowed(domain):
                await self.async_logger.warning(f"âŒ ä¸å…è®¸çš„åŸŸå: {domain}")
                return web.Response(
                    status=403,
                    text=json.dumps({"error": f"åŸŸå {domain} ä¸åœ¨å…è®¸åˆ—è¡¨ä¸­"})
                )
            
            # è·å–è¯·æ±‚æ•°æ®
            headers = dict(request.headers)
            request_data = await request.json()
            
            # è°ƒè¯•ï¼šæ‰“å°å®¢æˆ·ç«¯å‘é€çš„æ¶ˆæ¯
            await self.async_logger.debug(f"ğŸ” è°ƒè¯• - å®¢æˆ·ç«¯è¯·æ±‚æ•°æ®: {json.dumps(request_data, ensure_ascii=False, indent=2)}")
            
            # è¯·æ±‚ä½“å¤§å°æ£€æŸ¥
            if not await self._validate_request_size(request_data):
                return web.Response(
                    status=413,
                    text=json.dumps({"error": "è¯·æ±‚ä½“è¿‡å¤§ï¼Œè¯·å‡å°è¾“å…¥æ•°æ®å¤§å°æˆ–åˆ†æ‰¹å¤„ç†"})
                )
            
            # æ ¹æ®åŸŸåé…ç½®æˆ–è·¯å¾„è¯†åˆ«è®¤è¯ç±»å‹
            domain_config = self.allowed_domains.get(domain, {})
            if 'auth_type' in domain_config:
                # ä¼˜å…ˆä½¿ç”¨åŸŸåé…ç½®çš„è®¤è¯ç±»å‹
                auth_type = domain_config['auth_type']
            else:
                # å›é€€åˆ°è·¯å¾„æ¨¡å¼è¯†åˆ«
                auth_type = self.detect_auth_type_from_path(path)
            
            # å‡†å¤‡è®¤è¯å¤´
            forward_headers = self.prepare_auth_headers(headers, auth_type)
            
            # æ„å»ºç›®æ ‡URL
            target_url = self.get_target_url(domain, path)
            
            # åˆ¤æ–­æ˜¯å¦ä¸ºæµå¼è¯·æ±‚
            is_stream = request_data.get("stream", False)
            
            # Google APIç‰¹æ®Šå¤„ç†ï¼šæ£€æŸ¥URLä¸­æ˜¯å¦åŒ…å«streamGenerateContent
            if auth_type == "google" and "streamGenerateContent" in path:
                is_stream = True
                await self.async_logger.debug(f"ğŸ” è°ƒè¯• - Googleæµå¼è¯·æ±‚æ£€æµ‹: URLåŒ…å«streamGenerateContentï¼Œè®¾ç½®ä¸ºæµå¼")
            
            # è§£ææ¨¡å‹åç§°
            model = self.extract_model_from_request(request_data, path, auth_type)
            
            await self.async_logger.info(
                f"ğŸ“¡ åŠ¨æ€ä»£ç†è¯·æ±‚: {domain}{path}, è®¤è¯ç±»å‹: {auth_type}, æµå¼: {is_stream}, æ¨¡å‹: {model}"
            )
            
            # å‘é€è¯·æ±‚ï¼ˆå¸¦é‡è¯•æœºåˆ¶ï¼‰
            max_retries = 3
            retry_delay = 1  # åˆå§‹é‡è¯•å»¶è¿Ÿï¼ˆç§’ï¼‰
            
            for attempt in range(max_retries):
                try:
                    async with self.http_session.post(
                        target_url,
                        headers=forward_headers,
                        json=request_data
                    ) as resp:
                        if is_stream:
                            return await self._handle_stream_response(resp, request, auth_type, model, request_data)
                        else:
                            return await self._handle_non_stream_response(resp, auth_type, model, request_data)
                
                except (aiohttp.ClientError, asyncio.TimeoutError, TimeoutError) as e:
                    if attempt < max_retries - 1:  # ä¸æ˜¯æœ€åä¸€æ¬¡å°è¯•
                        await self.async_logger.warning(f"ğŸ”„ è¿æ¥å¤±è´¥ï¼Œç¬¬{attempt + 1}æ¬¡é‡è¯• (å…±{max_retries}æ¬¡): {str(e)}")
                        await asyncio.sleep(retry_delay)
                        retry_delay *= 2  # æŒ‡æ•°é€€é¿
                    else:
                        await self.async_logger.error(f"âŒ è¿æ¥å¤±è´¥ï¼Œå·²è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°: {str(e)}")
                        return web.Response(status=500, text=json.dumps({"error": "è¿æ¥è¶…æ—¶ï¼Œè¯·ç¨åé‡è¯•"}))
        
        except json.JSONDecodeError:
            await self.async_logger.error("âŒ æ— æ•ˆçš„è¯·æ±‚æ•°æ®æ ¼å¼")
            return web.Response(status=400, text=json.dumps({"error": "æ— æ•ˆçš„è¯·æ±‚æ•°æ®æ ¼å¼"}))
        except Exception as e:
            await self.async_logger.error(f"å¤„ç†åŠ¨æ€ä»£ç†è¯·æ±‚æ—¶å‘ç”Ÿé”™è¯¯: {e}\n{traceback.format_exc()}")
            return web.Response(status=500, text=json.dumps({"error": "æœåŠ¡å™¨å†…éƒ¨é”™è¯¯"}))
    
    async def _validate_request_size(self, request_data: Dict[str, Any]) -> bool:
        """éªŒè¯è¯·æ±‚ä½“å¤§å°ï¼ˆå…¼å®¹ OpenAI messages ä¸ Google contents.partsï¼‰"""
        max_chars = 8000000
        total_chars = 0

        # OpenAI/Anthropic é£æ ¼
        messages = request_data.get("messages", [])
        if isinstance(messages, list) and messages:
            try:
                for msg in messages:
                    if isinstance(msg, dict):
                        # åªç»Ÿè®¡ä¸»è¦æ–‡æœ¬
                        total_chars += len(str(msg.get("content", "")))
                    else:
                        total_chars += len(str(msg))
            except Exception:
                total_chars += len(str(messages))

        # Google Gemini é£æ ¼
        if total_chars == 0:
            contents = request_data.get("contents", [])
            if isinstance(contents, list) and contents:
                try:
                    for content in contents:
                        if isinstance(content, dict):
                            parts = content.get("parts", [])
                            if isinstance(parts, list):
                                for part in parts:
                                    if isinstance(part, dict):
                                        t = part.get("text")
                                        if isinstance(t, str):
                                            total_chars += len(t)
                except Exception:
                    total_chars += len(str(contents))

        if total_chars > max_chars:
            await self.async_logger.warning(
                f"âŒ è¯·æ±‚ä½“è¿‡å¤§: {total_chars} å­—ç¬¦ï¼Œè¶…è¿‡é™åˆ¶ {max_chars} å­—ç¬¦"
            )
            return False
        return True
    
    async def _handle_stream_response(self, resp: aiohttp.ClientResponse, request: web.Request,
                                    auth_type: str, model: str, request_data: Dict[str, Any]) -> web.StreamResponse:
        """å¤„ç†æµå¼å“åº”"""
        response = web.StreamResponse(
            status=resp.status,
            headers={'Content-Type': 'text/event-stream', 'Cache-Control': 'no-cache'}
        )
        await response.prepare(request)
        
        complete_response = ""
        complete_reasoning = ""
        response_id = None
        
        try:
            async for line in resp.content:
                # åŸæ ·é€ä¼ ä¸Šæ¸¸æ•°æ®ï¼Œä¿ç•™æ¢è¡Œä¸ç©ºè¡Œï¼ˆå¢åŠ å®¢æˆ·ç«¯æ–­å¼€é˜²æŠ¤ï¼‰
                transport = getattr(request, "transport", None)
                if transport is None or transport.is_closing():
                    await self.async_logger.info("ğŸ”Œ å®¢æˆ·ç«¯è¿æ¥å·²å…³é—­ï¼Œåœæ­¢ç»§ç»­å†™å…¥æµå¼æ•°æ®")
                    break
                try:
                    await response.write(line)
                    await response.drain()
                except (ConnectionResetError, BrokenPipeError, aiohttp.ClientConnectionResetError, asyncio.CancelledError):
                    await self.async_logger.info("ğŸ”Œ å®¢æˆ·ç«¯æ–­å¼€è¿æ¥ï¼Œåœæ­¢å†™å…¥")
                    break
                # å…¶ä»–å¼‚å¸¸äº¤ç”±å¤–å±‚æ•è·
                 
                # ä¸ºæ—¥å¿—ä¸è§£æå•ç‹¬æ„é€ å­—ç¬¦ä¸²ï¼Œä¸å½±å“é€ä¼ 
                try:
                    line_text = line.decode('utf-8', errors='ignore')
                except Exception:
                    line_text = ''
                line_str = line_text.strip()
                
                if line_str:
                    # è°ƒè¯•ï¼šæ‰“å°æ¥æ”¶åˆ°çš„æµå¼æ•°æ®
                    await self.async_logger.debug(f"ğŸ” è°ƒè¯• - æ¥æ”¶åˆ°æµå¼æ•°æ®: {line_str[:200]}...")
                    
                    # è§£æå“åº”å†…å®¹
                    if auth_type == "anthropic":
                        chunk_reasoning = ""
                        complete_response, response_id, chunk_reasoning = self._parse_anthropic_stream_chunk(
                            line_str, complete_response, response_id
                        )
                        if chunk_reasoning:
                            complete_reasoning += chunk_reasoning
                    elif auth_type == "google":
                        chunk_reasoning = ""
                        complete_response, response_id, chunk_reasoning = await self._parse_google_stream_chunk(
                            line_str, complete_response, response_id
                        )
                        if chunk_reasoning:
                            complete_reasoning += chunk_reasoning
                    else:
                        chunk_reasoning = ""
                        complete_response, response_id, chunk_reasoning = self._parse_openai_stream_chunk(
                            line_str, complete_response, response_id
                        )
                        if chunk_reasoning:
                            complete_reasoning += chunk_reasoning
        
        except Exception as e:
            await self.async_logger.error(f"æµå¼å“åº”å¤„ç†é”™è¯¯: {e}")
            await self.async_logger.error(f"é”™è¯¯è¯¦æƒ…: {traceback.format_exc()}")
        
        finally:
            # ä¿å­˜å¯¹è¯ - å¤„ç†ä¸åŒAPIæ ¼å¼çš„æ¶ˆæ¯è½¬æ¢
            if response_id and complete_response:
                # å¤„ç†ä¸åŒAPIæ ¼å¼çš„æ¶ˆæ¯è½¬æ¢
                messages = []
                if auth_type == "google":
                    # Google APIæ ¼å¼è½¬æ¢ï¼šcontents -> messages
                    if "contents" in request_data:
                        for content in request_data["contents"]:
                            # Google APIçš„contentsé€šå¸¸æ²¡æœ‰roleå­—æ®µï¼Œé»˜è®¤ä¸ºç”¨æˆ·æ¶ˆæ¯
                            # æå–ç”¨æˆ·æ¶ˆæ¯
                            text_parts = []
                            for part in content.get("parts", []):
                                if "text" in part:
                                    text_parts.append(part["text"])
                            if text_parts:
                                messages.append({
                                    "role": "user",
                                    "content": "\n".join(text_parts)
                                })
                else:
                    # OpenAI/Anthropicæ ¼å¼
                    messages = request_data.get('messages', [])
                
                # å­˜æ¡£ï¼šä»…åœ¨ OpenAI æˆ– Google ä¸”å­˜åœ¨ç»“æ„åŒ–æ€è€ƒæ—¶é™„åŠ <think>ï¼Œä¸åšå¯å‘å¼
                if auth_type in ("openai", "google") and complete_reasoning:
                    formatted_response = f"<think>\n{complete_reasoning}\n</think>\n\n{complete_response}"
                else:
                    formatted_response = complete_response
                
                # è°ƒè¯•ï¼šæ‰“å°æœ€ç»ˆä¿å­˜çš„å†…å®¹
                await self.async_logger.debug(f"ğŸ” è°ƒè¯• - æµå¼å“åº”æœ€ç»ˆå†…å®¹é•¿åº¦: {len(formatted_response)}")
                await self.async_logger.debug(f"ğŸ” è°ƒè¯• - æµå¼å“åº”å‰100å­—ç¬¦: {formatted_response[:100]}...")
                
                await self._queue_conversation(response_id, model, {
                    'request': request_data,
                    'response': formatted_response,
                    'reasoning': complete_reasoning,
                    'messages': messages
                })
        
        return response
    
    async def _handle_non_stream_response(self, resp: aiohttp.ClientResponse,
                                        auth_type: str, model: str, request_data: Dict[str, Any]) -> web.Response:
        """å¤„ç†éæµå¼å“åº”"""
        response_text = await resp.text()
        
        # è®°å½•ä¸Šæ¸¸å“åº”çŠ¶æ€
        if resp.status >= 400:
            await self.async_logger.warning(
                f"âš ï¸ ä¸Šæ¸¸æœåŠ¡å™¨è¿”å›é”™è¯¯: {resp.status} - {response_text[:200]}..."
            )
        
        try:
            response_json = json.loads(response_text)
            
            # è§£æå“åº”å†…å®¹
            complete_response = ""
            reasoning = ""
            
            if auth_type == "anthropic":
                complete_response = self._parse_anthropic_final_response(response_json)
            elif auth_type == "google":
                complete_response, reasoning = await self._parse_google_final_response(response_json)
            else:
                complete_response = self._parse_openai_final_response(response_json)
            
            # ä¿å­˜å¯¹è¯
            response_id = response_json.get('id', str(uuid.uuid4()))
            if complete_response:
                # ä¸åšæ€è€ƒæŠ½å–ï¼Œç›´æ¥ä¿å­˜åŸæ–‡
                # å¤„ç†ä¸åŒAPIæ ¼å¼çš„æ¶ˆæ¯è½¬æ¢
                messages = []
                if auth_type == "google":
                    # Google APIæ ¼å¼è½¬æ¢ï¼šcontents -> messages
                    # Google APIçš„contentsé€šå¸¸æ²¡æœ‰roleå­—æ®µï¼Œé»˜è®¤ä¸ºç”¨æˆ·æ¶ˆæ¯
                    if "contents" in request_data and isinstance(request_data["contents"], list):
                        for content in request_data["contents"]:
                            if isinstance(content, dict) and "parts" in content:
                                # æå–ç”¨æˆ·æ¶ˆæ¯ï¼ˆGoogle APIçš„contentsé»˜è®¤ä¸ºç”¨æˆ·è¾“å…¥ï¼‰
                                text_parts = []
                                parts = content.get("parts", [])
                                if isinstance(parts, list):
                                    for part in parts:
                                        if isinstance(part, dict) and "text" in part:
                                            text_parts.append(part["text"])
                                if text_parts:
                                    messages.append({
                                        "role": "user",
                                        "content": "\n".join(text_parts)
                                    })
                else:
                    # OpenAI/Anthropicæ ¼å¼
                    messages = request_data.get('messages', [])
                
                # è°ƒè¯•ï¼šæ‰“å°è½¬æ¢åçš„æ¶ˆæ¯
                await self.async_logger.debug(f"ğŸ” è°ƒè¯• - è½¬æ¢åçš„æ¶ˆæ¯æ ¼å¼: {json.dumps(messages, ensure_ascii=False, indent=2)}")
                
                # å¯¹éæµå¼ï¼šä»…åœ¨ OpenAI ä¸”å­˜åœ¨ç»“æ„åŒ– reasoning_content æ—¶ï¼ŒæŠŠæ€è€ƒå¹¶å…¥ response
                combined_response = (
                    f"<think>\n{reasoning}\n</think>\n\n{complete_response}"
                    if (auth_type in ["openai", "google"] and reasoning) else complete_response
                )
                
                # è°ƒè¯•ï¼šæ‰“å°ä¿å­˜çš„å¯¹è¯æ•°æ®
                conversation_to_save = {
                    'request': request_data,
                    'response': combined_response,
                    'reasoning': reasoning,
                    'messages': messages
                }
                await self.async_logger.debug(f"ğŸ” è°ƒè¯• - å‡†å¤‡ä¿å­˜çš„å¯¹è¯æ•°æ®: {json.dumps(conversation_to_save, ensure_ascii=False, indent=2)}")
                
                # ç¡®ä¿ä¼ é€’å®Œæ•´çš„è¯·æ±‚æ¶ˆæ¯
                await self._queue_conversation(response_id, model, conversation_to_save)
        
        except Exception as e:
            await self.async_logger.error(f"è§£æå“åº”æ—¶å‘ç”Ÿé”™è¯¯: {e}")
        
        return web.Response(
            status=resp.status,
            text=response_text,
            headers={'Content-Type': 'application/json'}
        )
    
    def _parse_openai_stream_chunk(self, line_str: str, complete_response: str, response_id: Optional[str]):
        """è§£æOpenAIæµå¼å“åº”å—"""
        complete_reasoning = ""
        
        if line_str.startswith("data: "):
            if line_str.strip() == "data: [DONE]":
                return complete_response, response_id, complete_reasoning
            
            try:
                json_data = line_str[6:].strip()
                if json_data:
                    json_chunk = json.loads(json_data)
                    if "id" in json_chunk and not response_id:
                        response_id = json_chunk["id"]
                    if "choices" in json_chunk and json_chunk["choices"]:
                        delta = json_chunk["choices"][0].get("delta", {})
                        rc = delta.get("reasoning_content")
                        # å…¼å®¹å¤šç§ç»“æ„çš„ reasoning_contentï¼Œä»…ç”¨äºå­˜æ¡£ç´¯åŠ 
                        if rc is not None:
                            try:
                                if isinstance(rc, str):
                                    complete_reasoning += rc
                                elif isinstance(rc, dict):
                                    # å¸¸è§å­—æ®µå°è¯•å±•å¼€
                                    for k in ["text", "content", "message"]:
                                        v = rc.get(k)
                                        if isinstance(v, str):
                                            complete_reasoning += v
                                        elif isinstance(v, list):
                                            complete_reasoning += "".join(
                                                x.get("text", "") if isinstance(x, dict) else str(x) for x in v
                                            )
                                    # parts ç»“æ„
                                    parts = rc.get("parts")
                                    if isinstance(parts, list):
                                        complete_reasoning += "".join(
                                            x.get("text", "") if isinstance(x, dict) else str(x) for x in parts
                                        )
                                elif isinstance(rc, list):
                                    complete_reasoning += "".join(
                                        x.get("text", "") if isinstance(x, dict) else str(x) for x in rc
                                    )
                                else:
                                    # å…œåº•åºåˆ—åŒ–
                                    complete_reasoning += str(rc)
                            except Exception:
                                pass
                        content = delta.get("content")
                        if content is not None:
                            complete_response += content
            except json.JSONDecodeError:
                pass
            except Exception:
                pass
        
        return complete_response, response_id, complete_reasoning
    
    def _parse_anthropic_stream_chunk(self, line_str: str, complete_response: str, response_id: Optional[str]):
        """è§£æAnthropicæµå¼å“åº”å—"""
        if line_str.startswith("data: "):
            if line_str.strip() == "data: [DONE]":
                return complete_response, response_id, ""
            
            try:
                json_chunk = json.loads(line_str[6:])
                
                if json_chunk.get("type") == "message_start" and "message" in json_chunk:
                    message = json_chunk["message"]
                    if "id" in message and not response_id:
                        response_id = message["id"]
                
                elif json_chunk.get("type") == "content_block_delta":
                    delta = json_chunk.get("delta", {})
                    if delta.get("type") == "text_delta":
                        text = delta.get("text", "")
                        complete_response += text
                        
            except json.JSONDecodeError:
                pass
        
        return complete_response, response_id, ""
    
    def _parse_openai_final_response(self, response_json: Dict[str, Any]) -> str:
        """è§£æOpenAIæœ€ç»ˆå“åº”å†…å®¹"""
        if "choices" in response_json and response_json["choices"]:
            choice = response_json["choices"][0]
            if isinstance(choice, dict) and "message" in choice and isinstance(choice["message"], dict):
                rc = choice["message"].get("reasoning_content", "")
                # å…¼å®¹å¯¹è±¡/æ•°ç»„å½¢å¼çš„ reasoning_content
                if not isinstance(rc, str) and rc:
                    try:
                        if isinstance(rc, dict):
                            buf = []
                            for k in ["text", "content", "message"]:
                                v = rc.get(k)
                                if isinstance(v, str):
                                    buf.append(v)
                                elif isinstance(v, list):
                                    buf.extend(x.get("text", "") if isinstance(x, dict) else str(x) for x in v)
                            parts = rc.get("parts")
                            if isinstance(parts, list):
                                buf.extend(x.get("text", "") if isinstance(x, dict) else str(x) for x in parts)
                            rc = "".join(buf).strip()
                        elif isinstance(rc, list):
                            rc = "".join(x.get("text", "") if isinstance(x, dict) else str(x) for x in rc).strip()
                        else:
                            rc = str(rc)
                    except Exception:
                        rc = ""
                reasoning_content = rc if isinstance(rc, str) else ""
                response_content = choice["message"].get("content", "")
                return f"<think>\n{reasoning_content}\n</think>\n\n{response_content}" if reasoning_content else response_content
        return ""
    
    async def _parse_google_final_response(self, response_json: Dict[str, Any]) -> tuple:
        """è§£æGoogle APIæœ€ç»ˆå“åº”å†…å®¹ï¼Œè¿”å›(å“åº”å†…å®¹, æ€è€ƒè¿‡ç¨‹)"""
        response_text = ""
        reasoning = ""
        
        # è°ƒè¯•ï¼šæ‰“å°å®Œæ•´å“åº”ç»“æ„
        import json
        await self.async_logger.debug(f"ğŸ” è°ƒè¯• - Google APIå®Œæ•´å“åº”: {json.dumps(response_json, ensure_ascii=False, indent=2)}")
        
        # æ£€æŸ¥æ˜¯å¦æœ‰é”™è¯¯çŠ¶æ€
        finish_reason = None
        if "candidates" in response_json and response_json["candidates"]:
            candidate = response_json["candidates"][0]
            await self.async_logger.debug(f"ğŸ” è°ƒè¯• - candidateç»“æ„: {json.dumps(candidate, ensure_ascii=False, indent=2)}")
            
            # è·å–finishReason
            finish_reason = candidate.get("finishReason")
            await self.async_logger.debug(f"ğŸ” è°ƒè¯• - finishReason: {finish_reason}")
            
            if finish_reason and finish_reason != "STOP":
                # å¤„ç†é”™è¯¯çŠ¶æ€
                error_message = f"APIé”™è¯¯: {finish_reason}"
                if finish_reason == "MAX_TOKENS":
                    error_message = "è¾¾åˆ°æœ€å¤§tokené™åˆ¶ï¼Œè¯·å‡å°‘è¾“å…¥å†…å®¹æˆ–è°ƒæ•´maxOutputTokenså‚æ•°"
                elif finish_reason == "SAFETY":
                    error_message = "å†…å®¹è¢«å®‰å…¨è¿‡æ»¤å™¨é˜»æ­¢"
                elif finish_reason == "RECITATION":
                    error_message = "æ£€æµ‹åˆ°å†…å®¹é‡å¤"
                
                response_text = error_message
                await self.async_logger.warning(f"âš ï¸ Google APIè¿”å›é”™è¯¯çŠ¶æ€: {finish_reason}")
                return response_text, reasoning
            
            if isinstance(candidate, dict) and "content" in candidate:
                content = candidate["content"]
                await self.async_logger.debug(f"ğŸ” è°ƒè¯• - contentç»“æ„: {json.dumps(content, ensure_ascii=False, indent=2)}")
                
                # æ£€æŸ¥contentæ˜¯å¦æœ‰partså­—æ®µ
                if isinstance(content, dict) and "parts" in content:
                    parts = content["parts"]
                    if isinstance(parts, list) and parts:
                        # åˆ†åˆ«å¤„ç†æ€è€ƒè¿‡ç¨‹å’Œå“åº”å†…å®¹
                        text_parts = []
                        thought_parts = []
                        
                        for part in parts:
                            if isinstance(part, dict):
                                is_thought_part = False
                                # ä¼˜å…ˆè§£æç»“æ„åŒ–æ€è€ƒï¼špart.thinking.thought
                                if "thinking" in part and isinstance(part.get("thinking"), dict):
                                    t = part["thinking"].get("thought")
                                    if isinstance(t, str) and t:
                                        thought_parts.append(t)
                                        is_thought_part = True
                                # å…¼å®¹æ—§ç»“æ„ï¼špart.thought == True ä¸” text å±äºæ€è€ƒ
                                elif "thought" in part and isinstance(part.get("thought"), bool) and part.get("thought") is True:
                                    t = part.get("text", "")
                                    if isinstance(t, str) and t:
                                        thought_parts.append(t)
                                        is_thought_part = True
                                # æ™®é€šæ–‡æœ¬å†…å®¹ï¼ˆé¢å‘ç”¨æˆ·å¯è§çš„å›ç­”ï¼‰ï¼Œä»…åœ¨éæ€è€ƒç‰‡æ®µæ—¶çº³å…¥
                                if (not is_thought_part) and "text" in part and isinstance(part.get("text"), str):
                                    text_parts.append(part["text"])
                        
                        # åˆå¹¶å“åº”å†…å®¹
                        response_text = "\n".join(text_parts)
                        
                        # åˆå¹¶æ€è€ƒè¿‡ç¨‹ï¼ˆä»…ä¾èµ–ç»“æ„åŒ–å­—æ®µï¼‰
                        if thought_parts:
                            reasoning = "\n".join(thought_parts).strip()
                
                # å¦‚æœcontentæ²¡æœ‰partså­—æ®µä½†æœ‰å…¶ä»–å­—æ®µï¼Œæ£€æŸ¥æ˜¯å¦ç›´æ¥åŒ…å«æ–‡æœ¬
                elif isinstance(content, dict):
                    # æ£€æŸ¥æ˜¯å¦æœ‰ç›´æ¥çš„textå­—æ®µ
                    if "text" in content:
                        response_text = content["text"]
                    # æ£€æŸ¥æ˜¯å¦æœ‰thoughtå­—æ®µ
                    if "thought" in content:
                        reasoning = content["thought"]
                    
                    # å¦‚æœcontentåªæœ‰roleå­—æ®µï¼Œå¯èƒ½å“åº”å†…å®¹ä¸ºç©º
                    if not response_text and "role" in content:
                        await self.async_logger.debug(f"ğŸ” è°ƒè¯• - contentåªæœ‰roleå­—æ®µï¼Œå“åº”å†…å®¹ä¸ºç©º")
        
        # è°ƒè¯•ï¼šæ‰“å°æå–ç»“æœ
        await self.async_logger.debug(f"ğŸ” è°ƒè¯• - æå–çš„å“åº”å†…å®¹é•¿åº¦: {len(response_text)}")
        await self.async_logger.debug(f"ğŸ” è°ƒè¯• - æå–çš„æ€è€ƒè¿‡ç¨‹é•¿åº¦: {len(reasoning)}")
        
        return response_text, reasoning
    
    async def _parse_google_stream_chunk(self, line_str: str, complete_response: str, response_id: Optional[str]):
        """è§£æGoogle APIæµå¼å“åº”å—"""
        complete_reasoning = ""
        
        # è°ƒè¯•ï¼šæ‰“å°æ¥æ”¶åˆ°çš„åŸå§‹æ•°æ®
        await self.async_logger.debug(f"ğŸ” è°ƒè¯• - Googleæµå¼åŸå§‹æ•°æ®: {repr(line_str[:100])}")
        
        # Google APIæµå¼æ•°æ®å¯èƒ½ä¸å¸¦ "data: " å‰ç¼€ï¼Œç›´æ¥æ˜¯JSONç‰‡æ®µ
        json_data = line_str.strip()
        if json_data.startswith("data: "):
            if json_data.strip() == "data: [DONE]":
                return complete_response, response_id, complete_reasoning
            json_data = json_data[6:].strip()
        
        # è·³è¿‡ç©ºè¡Œå’ŒéJSONæ•°æ®
        if not json_data or json_data in ['{', '}', '[', ']', ',']:
            return complete_response, response_id, complete_reasoning
            
        # Google APIè¿”å›çš„æ˜¯JSONç‰‡æ®µï¼Œéœ€è¦ç‰¹æ®Šå¤„ç†
        try:
            # å°è¯•ç›´æ¥è§£æå®Œæ•´JSON
            if json_data.startswith('{') and json_data.endswith('}'):
                json_chunk = json.loads(json_data)
                await self.async_logger.debug(f"ğŸ” è°ƒè¯• - è§£æå®Œæ•´JSONæˆåŠŸ")
                
                # è·å–response_id
                if not response_id and "responseId" in json_chunk:
                    response_id = json_chunk["responseId"]
                    await self.async_logger.debug(f"ğŸ” è°ƒè¯• - è·å–åˆ°responseId: {response_id}")
                
                # è§£æcandidatesä¸­çš„å†…å®¹
                if "candidates" in json_chunk and json_chunk["candidates"]:
                    candidate = json_chunk["candidates"][0]
                    if "content" in candidate and "parts" in candidate["content"]:
                        for part in candidate["content"]["parts"]:
                            is_thought_part = False
                            # æ–°ç»“æ„ï¼šthinking å¯¹è±¡é‡ŒåŒ…å«æ€è€ƒæ–‡æœ¬
                            if "thinking" in part and isinstance(part.get("thinking"), dict):
                                t = part["thinking"].get("thought")
                                if isinstance(t, str) and t:
                                    complete_reasoning += t
                                    is_thought_part = True
                                    await self.async_logger.debug(f"ğŸ” è°ƒè¯• - æå–æ€ç»´é“¾(part.thinking.thought): {t[:50]}...")
                            # æ—§ç»“æ„ï¼šthought ä¸º True æ—¶ï¼Œtext å±äºæ€è€ƒ
                            elif "thought" in part and isinstance(part.get("thought"), bool) and part.get("thought") is True:
                                t = part.get("text", "")
                                if isinstance(t, str) and t:
                                    complete_reasoning += t
                                    is_thought_part = True
                                    await self.async_logger.debug(f"ğŸ” è°ƒè¯• - æå–æ€ç»´é“¾(part.thought=true): {t[:50]}...")
                            # æ™®é€šæ–‡æœ¬ç‰‡æ®µï¼Œè®¡å…¥æœ€ç»ˆå¯è§å›ç­”ï¼ˆä»…éæ€è€ƒç‰‡æ®µï¼‰
                            if (not is_thought_part) and "text" in part and isinstance(part.get("text"), str):
                                text_content = part["text"]
                                complete_response += text_content
                                await self.async_logger.debug(f"ğŸ” è°ƒè¯• - æå–æ–‡æœ¬å†…å®¹: {text_content[:50]}...")
            else:
                # å¯¹äºJSONç‰‡æ®µï¼Œå°è¯•æå–å…³é”®ä¿¡æ¯
                if '"text":' in json_data:
                    # è‹¥ç‰‡æ®µåŒ…å«æ€è€ƒæ ‡è®°ï¼Œåˆ™è·³è¿‡æŠŠ text å¹¶å…¥å¯è§ç­”æ¡ˆ
                    if ('"thought": true' in json_data) or ('"thinking"' in json_data):
                        await self.async_logger.debug("ğŸ” è°ƒè¯• - ç‰‡æ®µåŒ…å«æ€è€ƒæ ‡è®°ï¼Œè·³è¿‡å°† text å¹¶å…¥å¯è§ç­”æ¡ˆ")
                    else:
                        # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æå–textå†…å®¹
                        import re
                        text_match = re.search(r'"text":\s*"([^"]*)"', json_data)
                        if text_match:
                            text_content = text_match.group(1)
                            complete_response += text_content
                            await self.async_logger.debug(f"ğŸ” è°ƒè¯• - ä»ç‰‡æ®µæå–æ–‡æœ¬: {text_content[:50]}...")
                
                if '"responseId":' in json_data and not response_id:
                    # æå–responseId
                    import re
                    id_match = re.search(r'"responseId":\s*"([^"]*)"', json_data)
                    if id_match:
                        response_id = id_match.group(1)
                        await self.async_logger.debug(f"ğŸ” è°ƒè¯• - ä»ç‰‡æ®µæå–responseId: {response_id}")
                
        except json.JSONDecodeError as e:
            await self.async_logger.debug(f"ğŸ” è°ƒè¯• - JSONè§£æå¤±è´¥: {str(e)[:100]}")
            # å°è¯•å¤„ç†SSEæ ¼å¼ï¼šdata: {json}
            if line_str.startswith("data: ") and len(line_str) > 6:
                sse_data = line_str[6:].strip()
                if sse_data and sse_data != "[DONE]":
                    try:
                        json_chunk = json.loads(sse_data)
                        await self.async_logger.debug(f"ğŸ” è°ƒè¯• - SSEæ ¼å¼è§£ææˆåŠŸ")
                        
                        # è·å–response_id
                        if not response_id and "responseId" in json_chunk:
                            response_id = json_chunk["responseId"]
                            await self.async_logger.debug(f"ğŸ” è°ƒè¯• - è·å–åˆ°responseId: {response_id}")
                        
                        # è§£æcandidatesä¸­çš„å†…å®¹
                        if "candidates" in json_chunk and json_chunk["candidates"]:
                            candidate = json_chunk["candidates"][0]
                            if "content" in candidate and "parts" in candidate["content"]:
                                for part in candidate["content"]["parts"]:
                                    is_thought_part = False
                                    if "thinking" in part and isinstance(part.get("thinking"), dict):
                                        t = part["thinking"].get("thought")
                                        if isinstance(t, str) and t:
                                            complete_reasoning += t
                                            is_thought_part = True
                                    elif "thought" in part and isinstance(part.get("thought"), bool) and part.get("thought") is True:
                                        t = part.get("text", "")
                                        if isinstance(t, str) and t:
                                            complete_reasoning += t
                                            is_thought_part = True
                                    if (not is_thought_part) and "text" in part:
                                        text_content = part["text"]
                                        complete_response += text_content
                                        await self.async_logger.debug(f"ğŸ” è°ƒè¯• - æå–æ–‡æœ¬å†…å®¹: {text_content[:50]}...")
                    except json.JSONDecodeError:
                        await self.async_logger.debug(f"ğŸ” è°ƒè¯• - SSEæ•°æ®ä»ç„¶ä¸æ˜¯æœ‰æ•ˆJSON")
        except Exception as e:
            await self.async_logger.error(f"Googleæµå¼è§£æé”™è¯¯: {e}")
            await self.async_logger.error(f"é”™è¯¯è¯¦æƒ…: {traceback.format_exc()}")
        
        return complete_response, response_id, complete_reasoning
    
    def _parse_anthropic_final_response(self, response_json: Dict[str, Any]) -> str:
        """è§£æAnthropicæœ€ç»ˆå“åº”å†…å®¹"""
        content_list = response_json.get("content", [])
        response_content = ""
        
        if isinstance(content_list, list) and content_list:
            for content_item in content_list:
                if isinstance(content_item, dict):
                    if content_item.get("type") == "text":
                        response_content += content_item.get("text", "")
        
        return response_content
    

    

    
    async def _queue_conversation(self, id: str, model: str, conversation: dict):
        """å°†å¯¹è¯åŠ å…¥é˜Ÿåˆ—ç­‰å¾…æ‰¹é‡ä¿å­˜"""
        try:
            conversation_data = {
                'id': id,
                'model': model,
                'conversation': conversation,
                'timestamp': time.time()
            }
            await self.conversation_queue.put(conversation_data)
        except Exception as e:
            await self.async_logger.error(f"åŠ å…¥å¯¹è¯é˜Ÿåˆ—å¤±è´¥: {e}")
    
    async def _batch_save_conversations(self):
        """æ‰¹é‡ä¿å­˜å¯¹è¯"""
        batch = []
        last_save_time = time.time()
        
        while True:
            try:
                # ç­‰å¾…æ–°çš„å¯¹è¯æ•°æ®æˆ–è¶…æ—¶
                try:
                    conversation_data = await asyncio.wait_for(
                        self.conversation_queue.get(), 
                        timeout=self.batch_timeout
                    )
                    batch.append(conversation_data)
                except asyncio.TimeoutError:
                    pass
                
                current_time = time.time()
                
                # æ£€æŸ¥æ˜¯å¦éœ€è¦ä¿å­˜æ‰¹æ¬¡
                should_save = (
                    len(batch) >= self.batch_size or
                    (batch and current_time - last_save_time >= self.batch_timeout)
                )
                
                if should_save and batch:
                    await self._save_batch(batch)
                    batch = []
                    last_save_time = current_time
                    
            except Exception as e:
                await self.async_logger.error(f"æ‰¹é‡ä¿å­˜å¯¹è¯æ—¶å‘ç”Ÿé”™è¯¯: {e}")
                await asyncio.sleep(1)
    
    async def _save_batch(self, batch):
        """ä¿å­˜ä¸€æ‰¹å¯¹è¯ï¼ˆå¤ç”¨å•ä¸ª DB è¿æ¥æå‡æ€§èƒ½ï¼‰"""
        db_conn = None
        try:
            db_conn = await get_db_connection()
            for conversation_data in batch:
                # æ£€æŸ¥æ•°æ®ç»“æ„
                if not isinstance(conversation_data, dict):
                    await self.async_logger.error(f"æ— æ•ˆçš„å¯¹è¯æ•°æ®ç±»å‹: {type(conversation_data)}")
                    continue
                
                if 'conversation' not in conversation_data:
                    await self.async_logger.error(f"å¯¹è¯æ•°æ®ç¼ºå°‘conversationå­—æ®µ: {conversation_data}")
                    continue
                
                conversation = conversation_data['conversation']
                if not isinstance(conversation, dict):
                    await self.async_logger.error(f"conversationå­—æ®µç±»å‹é”™è¯¯: {type(conversation)}")
                    continue
                
                # æ ¼å¼åŒ–ä¸ºShareGPTæ ¼å¼
                # ä¼˜å…ˆä½¿ç”¨conversationä¸­çš„messagesï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨requestä¸­çš„messages
                messages = conversation.get('messages', conversation.get('request', {}).get('messages', []))
                
                # è°ƒè¯•ï¼šæ‰“å°æ ¼å¼åŒ–å‰çš„æ•°æ®
                await self.async_logger.debug(f"ğŸ” è°ƒè¯• - æ ¼å¼åŒ–å‰çš„æ¶ˆæ¯: {json.dumps(messages, ensure_ascii=False, indent=2)}")
                await self.async_logger.debug(f"ğŸ” è°ƒè¯• - å“åº”å†…å®¹: {conversation.get('response', '')}")
                
                sharegpt_data = format_to_sharegpt(
                    conversation_data.get('model', 'unknown'),
                    messages,
                    conversation.get('response', ''),
                    conversation.get('request', {})
                )
                
                # è°ƒè¯•ï¼šæ‰“å°æ ¼å¼åŒ–åçš„æ•°æ®
                await self.async_logger.debug(f"ğŸ” è°ƒè¯• - æ ¼å¼åŒ–åçš„ShareGPTæ•°æ®: {json.dumps(sharegpt_data, ensure_ascii=False, indent=2)}")
                
                # ä¿å­˜åˆ°æ•°æ®åº“ï¼ˆå¤ç”¨è¿æ¥ï¼‰
                await save_conversation_async(
                    db_conn,
                    conversation_data.get('id', str(uuid.uuid4())),
                    conversation_data.get('model', 'unknown'),
                    sharegpt_data
                )
            
            await self.async_logger.info(f"âœ… æˆåŠŸä¿å­˜ {len(batch)} æ¡å¯¹è¯")
            
        except Exception as e:
            await self.async_logger.error(f"ä¿å­˜å¯¹è¯æ‰¹æ¬¡å¤±è´¥: {e}\n{traceback.format_exc()}")
        finally:
            if db_conn is not None:
                try:
                    await db_conn.close()
                except Exception:
                    pass
    
    async def handle_health_check(self, request: web.Request) -> web.Response:
        """å¥åº·æ£€æŸ¥ç«¯ç‚¹"""
        return web.Response(
            status=200,
            text=json.dumps({
                "status": "healthy",
                "service": "dynamic-proxy",
                "timestamp": time.time()
            }),
            headers={'Content-Type': 'application/json'}
        )

if __name__ == "__main__":
    args = parse_args()
    proxy = DynamicProxyEndpoint(port=args.port)
    try:
        web.run_app(proxy.app, host="0.0.0.0", port=args.port)
    except Exception as e:
        logger.error(f"å¯åŠ¨æœåŠ¡å™¨æ—¶å‘ç”Ÿè‡´å‘½é”™è¯¯: {e}", exc_info=True)
    finally:
        logger.info("æœåŠ¡å™¨å·²å…³é—­")