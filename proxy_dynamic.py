import json
import logging
import time
import asyncio
import uuid
from aiohttp import web
import aiohttp
import argparse
from typing import Dict, Any, Optional, Set
import traceback
import sqlite3
import aiosqlite
from utils import format_to_sharegpt, init_async_logger, get_async_logger, init_db_path, get_db_connection, save_conversation_async
import re
from aiohttp.web_middlewares import middleware
from collections import defaultdict, deque
import hashlib
from urllib.parse import urlparse

# è‡ªå®šä¹‰æ—¥å¿—è¿‡æ»¤å™¨ï¼Œå±è”½æ¢é’ˆè¯·æ±‚çš„æ—¥å¿—
class ProbeRequestFilter(logging.Filter):
    """è¿‡æ»¤æ¢é’ˆè¯·æ±‚çš„æ—¥å¿—è®°å½•"""
    
    def __init__(self):
        super().__init__()
        # å®šä¹‰æ¢é’ˆè¯·æ±‚çš„ç‰¹å¾æ¨¡å¼
        self.probe_patterns = [
            r'GET / HTTP',  # æ ¹è·¯å¾„æ¢æµ‹
            r'GET /favicon.ico',  # å›¾æ ‡è¯·æ±‚
            r'GET /\.well-known/',  # å®‰å…¨æ–‡ä»¶æ¢æµ‹
            r'GET /locales/',  # æœ¬åœ°åŒ–æ–‡ä»¶æ¢æµ‹
            r'UNKNOWN / HTTP',  # æœªçŸ¥åè®®è¯·æ±‚
            r'CensysInspect',  # Censysæ‰«æå™¨
            r'Mozilla/5\.0.*Chrome/90\.0\.4430\.85',  # ç‰¹å®šçš„æ¢é’ˆUser-Agent
            r'Go-http-client',  # Goå®¢æˆ·ç«¯æ¢æµ‹
            r'BadHttpMessage',  # HTTPåè®®é”™è¯¯
            r'BadStatusLine',  # HTTPçŠ¶æ€è¡Œé”™è¯¯
            r'Invalid method encountered',  # æ— æ•ˆHTTPæ–¹æ³•
            r'Pause on PRI/Upgrade',  # HTTP/2å‡çº§é”™è¯¯
            r"'NoneType' object is not callable",  # ç©ºå¯¹è±¡è°ƒç”¨é”™è¯¯
            r'Task exception was never retrieved',  # å¼‚æ­¥ä»»åŠ¡å¼‚å¸¸
            r'Error handling request',  # è¯·æ±‚å¤„ç†é”™è¯¯
            r'193\.34\.212\.110',  # ç‰¹å®šçš„æ¢é’ˆIP
            r'185\.191\.127\.222',  # ç‰¹å®šçš„æ¢é’ˆIP
            r'162\.142\.125\.124',  # ç‰¹å®šçš„æ¢é’ˆIP
            r'194\.62\.248\.69',  # ç‰¹å®šçš„æ¢é’ˆIP
            r'209\.38\.219\.203',  # ç‰¹å®šçš„æ¢é’ˆIP
            r'\\x16\\x03\\x01',  # SSL/TLSæ¡æ‰‹æ•°æ®
            r'bytearray\(b\'\\x16\\x03\\x01',  # SSLæ¡æ‰‹å­—èŠ‚æ•°ç»„
        ]
        
        # ç¼–è¯‘æ­£åˆ™è¡¨è¾¾å¼ä»¥æé«˜æ€§èƒ½
        self.compiled_patterns = [re.compile(pattern) for pattern in self.probe_patterns]
    
    def filter(self, record):
        """è¿‡æ»¤æ—¥å¿—è®°å½•"""
        message = record.getMessage()
        
        # æ£€æŸ¥æ˜¯å¦åŒ¹é…ä»»ä½•æ¢é’ˆæ¨¡å¼
        for pattern in self.compiled_patterns:
            if pattern.search(message):
                return False  # è¿‡æ»¤æ‰è¿™æ¡æ—¥å¿—
        
        return True  # ä¿ç•™è¿™æ¡æ—¥å¿—

def parse_args():
    parser = argparse.ArgumentParser(description="åŠ¨æ€ä»£ç†ç«¯ç‚¹æœåŠ¡å™¨")
    parser.add_argument("--port", type=int, default=8080, help="æœåŠ¡å™¨ç«¯å£")
    parser.add_argument("--log-level", default="INFO", choices=["DEBUG", "INFO", "WARNING", "ERROR"], help="æ—¥å¿—çº§åˆ«")
    return parser.parse_args()

args = parse_args()

# é…ç½®æ—¥å¿—
logging.basicConfig(level=getattr(logging, args.log_level.upper()))
logger = logging.getLogger(__name__)

# æ¸…é™¤ç°æœ‰çš„å¤„ç†å™¨
for handler in logger.handlers[:]:
    logger.removeHandler(handler)

# åˆ›å»ºæ¢é’ˆè¿‡æ»¤å™¨
probe_filter = ProbeRequestFilter()

# ä¸ºç›¸å…³çš„æ—¥å¿—å™¨æ·»åŠ è¿‡æ»¤å™¨
aiohttp_access_logger = logging.getLogger('aiohttp.access')
aiohttp_server_logger = logging.getLogger('aiohttp.server')
asyncio_logger = logging.getLogger('asyncio')

# ä¸ºæ¯ä¸ªæ—¥å¿—å™¨æ·»åŠ è¿‡æ»¤å™¨
for log in [aiohttp_access_logger, aiohttp_server_logger, asyncio_logger]:
    log.addFilter(probe_filter)
    # ä¹Ÿä¸ºç°æœ‰çš„å¤„ç†å™¨æ·»åŠ è¿‡æ»¤å™¨
    for handler in log.handlers:
        handler.addFilter(probe_filter)

# å…¨å±€å¼‚æ­¥å¼‚å¸¸å¤„ç†å™¨
def handle_asyncio_exception(loop, context):
    """å¤„ç†asyncioä¸­æœªæ•è·çš„å¼‚å¸¸"""
    exception = context.get('exception')
    if exception:
        # æ£€æŸ¥æ˜¯å¦æ˜¯æ¢é’ˆç›¸å…³çš„å¼‚å¸¸
        error_message = str(exception)
        probe_filter_instance = ProbeRequestFilter()
        
        # åˆ›å»ºä¸€ä¸ªæ¨¡æ‹Ÿçš„æ—¥å¿—è®°å½•æ¥æµ‹è¯•è¿‡æ»¤å™¨
        class MockRecord:
            def getMessage(self):
                return error_message
        
        mock_record = MockRecord()
        if not probe_filter_instance.filter(mock_record):
            return  # å¦‚æœæ˜¯æ¢é’ˆç›¸å…³å¼‚å¸¸ï¼Œå¿½ç•¥å®ƒ
        
        logger.error(f"æœªæ•è·çš„asyncioå¼‚å¸¸: {exception}", exc_info=exception)
    else:
        logger.error(f"æœªæ•è·çš„asyncioé”™è¯¯: {context}")

@middleware
async def probe_request_middleware(request, handler):
    """ä¸­é—´ä»¶ï¼šè¿‡æ»¤æ¢é’ˆè¯·æ±‚"""
    # è·å–å®¢æˆ·ç«¯IP
    client_ip = request.remote
    if 'X-Forwarded-For' in request.headers:
        client_ip = request.headers['X-Forwarded-For'].split(',')[0].strip()
    elif 'X-Real-IP' in request.headers:
        client_ip = request.headers['X-Real-IP']
    
    # æ£€æŸ¥æ˜¯å¦ä¸ºæ¢é’ˆè¯·æ±‚
    user_agent = request.headers.get('User-Agent', '')
    path = request.path
    method = request.method
    
    # æ¢é’ˆè¯·æ±‚ç‰¹å¾
    probe_indicators = [
        path in ['/', '/favicon.ico'],
        path.startswith('/.well-known/'),
        path.startswith('/locales/'),
        'CensysInspect' in user_agent,
        'Go-http-client' in user_agent,
        method not in ['GET', 'POST', 'PUT', 'DELETE', 'PATCH', 'OPTIONS'],
        # ç‰¹å®šçš„æ¢é’ˆIPåœ°å€
        client_ip in ['193.34.212.110', '185.191.127.222', '162.142.125.124', '194.62.248.69', '209.38.219.203']
    ]
    
    if any(probe_indicators):
        # é™é»˜è¿”å›404ï¼Œä¸è®°å½•æ—¥å¿—
        return web.Response(status=404, text="Not Found")
    
    # æ­£å¸¸è¯·æ±‚ï¼Œç»§ç»­å¤„ç†
    return await handler(request)

class DynamicProxyEndpoint:
    """åŠ¨æ€ä»£ç†ç«¯ç‚¹ï¼Œæ— éœ€é…ç½®æ–‡ä»¶"""
    
    def __init__(self, port: int = 8080):
        self.port = port
        self.app = web.Application(middlewares=[probe_request_middleware])
        self.setup_routes()
        
        # æ€§èƒ½ä¼˜åŒ–ç›¸å…³
        self.http_session = None
        self.async_logger = None
        self.conversation_queue = None
        self.batch_size = 10
        self.batch_timeout = 5.0
        
        # åŸŸåç™½åå•å’Œè®¤è¯æ˜ å°„
        self.allowed_domains = {
            'api.openai.com': {'auth_type': 'openai', 'https': True},
            'api.anthropic.com': {'auth_type': 'anthropic', 'https': True},
            'api.moonshot.cn': {'auth_type': 'anthropic', 'https': True},
            'api.deepseek.com': {'auth_type': 'openai', 'https': True},
            'api.siliconflow.cn': {'auth_type': 'openai', 'https': True},
            'dashscope.aliyuncs.com': {'auth_type': 'openai', 'https': True},
            'models.inference.ai.azure.com': {'auth_type': 'openai', 'https': True},
            'deepsearch.jina.ai': {'auth_type': 'openai', 'https': True},
            # å†…ç½‘åœ°å€
            '36.141.21.137:9081': {'auth_type': 'openai', 'https': False},
            'group.sx.10086.cn': {'auth_type': 'openai', 'https': False},
        }
        
        # è®¾ç½®åº”ç”¨å¯åŠ¨å’Œæ¸…ç†äº‹ä»¶
        self.app.on_startup.append(self.init_async_resources)
        self.app.on_cleanup.append(self.cleanup_resources)
    
    def setup_routes(self):
        """è®¾ç½®è·¯ç”±"""
        # åŠ¨æ€ä»£ç†è·¯ç”±ï¼š/{domain}/{path:.*}
        self.app.router.add_post("/{domain}/{path:.*}", self.handle_dynamic_proxy)
        self.app.router.add_get("/health", self.handle_health_check)
        
    async def init_async_resources(self, app):
        """åˆå§‹åŒ–å¼‚æ­¥èµ„æº"""
        # è®¾ç½®å…¨å±€å¼‚æ­¥å¼‚å¸¸å¤„ç†å™¨
        loop = asyncio.get_event_loop()
        loop.set_exception_handler(handle_asyncio_exception)
        
        # åˆå§‹åŒ–å¼‚æ­¥æ—¥å¿—
        await asyncio.to_thread(init_async_logger, "proxy_dynamic", "proxy_dynamic.log", getattr(logging, args.log_level.upper()))
        self.async_logger = get_async_logger()
        if self.async_logger is None:
            raise ValueError("Failed to initialize async_logger")
        await self.async_logger.info("âœ… å¼‚æ­¥æ—¥å¿—åˆå§‹åŒ–å®Œæˆ")
        
        # åˆå§‹åŒ–æ•°æ®åº“
        await init_db_path("interactions.db")
        await self.async_logger.info("âœ… æ•°æ®åº“åˆå§‹åŒ–å®Œæˆ")
        
        # åˆå§‹åŒ–HTTPè¿æ¥æ± 
        connector = aiohttp.TCPConnector(
            limit=100,
            limit_per_host=30,
            ttl_dns_cache=300,
            use_dns_cache=True,
            keepalive_timeout=30,
            enable_cleanup_closed=True
        )
        
        timeout = aiohttp.ClientTimeout(
            total=600,
            connect=30,
            sock_connect=30,
            sock_read=600
        )
        
        self.http_session = aiohttp.ClientSession(
            connector=connector,
            timeout=timeout,
            headers={'User-Agent': 'DynamicProxy/1.0'}
        )
        
        await self.async_logger.info("âœ… HTTPè¿æ¥æ± åˆå§‹åŒ–å®Œæˆ")
        
        # åˆå§‹åŒ–æ‰¹é‡å¤„ç†é˜Ÿåˆ—
        self.conversation_queue = asyncio.Queue(maxsize=1000)
        asyncio.create_task(self._batch_save_conversations())
        await self.async_logger.info("âœ… æ‰¹é‡å¤„ç†é˜Ÿåˆ—åˆå§‹åŒ–å®Œæˆ")
        
        await self.async_logger.info("ğŸš€ åŠ¨æ€ä»£ç†æœåŠ¡å™¨å¯åŠ¨å®Œæˆ")
    
    async def cleanup_resources(self, app):
        """æ¸…ç†èµ„æº"""
        if self.http_session:
            await self.http_session.close()
        if self.async_logger:
            await self.async_logger.info("ğŸ”„ èµ„æºæ¸…ç†å®Œæˆ")
    
    def detect_auth_type_from_path(self, path: str) -> str:
        """æ ¹æ®è·¯å¾„æ¨¡å¼è¯†åˆ«è®¤è¯ç±»å‹"""
        # æ–¹æ¡ˆB: è·¯å¾„æ¨¡å¼è¯†åˆ«
        if "/anthropic/" in path or "/v1/messages" in path:
            return "anthropic"
        elif "/v1/chat/completions" in path or "/chat/completions" in path:
            return "openai"
        elif "/v1/embeddings" in path:
            return "openai"
        elif "/v1/rerank" in path:
            return "openai"
        else:
            # é»˜è®¤ä½¿ç”¨openaiæ ¼å¼
            return "openai"
    
    def prepare_auth_headers(self, request_headers: Dict[str, str], auth_type: str) -> Dict[str, str]:
        """æ ¹æ®è®¤è¯ç±»å‹å‡†å¤‡è¯·æ±‚å¤´"""
        base_headers = {"Content-Type": "application/json"}
        
        if auth_type == "anthropic":
            # Anthropicè®¤è¯å¤„ç†
            auth_header = request_headers.get("Authorization", "")
            api_key = ""
            if auth_header.startswith("Bearer "):
                api_key = auth_header.replace("Bearer ", "").strip()
            elif request_headers.get("x-api-key"):
                api_key = request_headers.get("x-api-key")
            
            base_headers["Authorization"] = f"Bearer {api_key}"
        else:
            # OpenAIåŠå…¶ä»–APIè®¤è¯å¤„ç†
            base_headers["Authorization"] = request_headers.get("Authorization", "")
        
        return base_headers
    
    def is_domain_allowed(self, domain: str) -> bool:
        """æ£€æŸ¥åŸŸåæ˜¯å¦åœ¨ç™½åå•ä¸­"""
        return domain in self.allowed_domains
    
    def get_target_url(self, domain: str, path: str) -> str:
        """æ„å»ºç›®æ ‡URL"""
        domain_config = self.allowed_domains.get(domain, {'https': True})
        protocol = 'https' if domain_config.get('https', True) else 'http'
        return f"{protocol}://{domain}{path}"
    
    async def handle_dynamic_proxy(self, request: web.Request) -> web.StreamResponse:
        """å¤„ç†åŠ¨æ€ä»£ç†è¯·æ±‚"""
        try:
            # è§£æURLå‚æ•°
            domain = request.match_info['domain']
            path = '/' + request.match_info['path']
            
            # å®‰å…¨æ£€æŸ¥ï¼šéªŒè¯åŸŸåç™½åå•
            if not self.is_domain_allowed(domain):
                await self.async_logger.warning(f"âŒ ä¸å…è®¸çš„åŸŸå: {domain}")
                return web.Response(
                    status=403,
                    text=json.dumps({"error": f"åŸŸå {domain} ä¸åœ¨å…è®¸åˆ—è¡¨ä¸­"})
                )
            
            # è·å–è¯·æ±‚æ•°æ®
            headers = dict(request.headers)
            request_data = await request.json()
            
            # è¯·æ±‚ä½“å¤§å°æ£€æŸ¥
            if not await self._validate_request_size(request_data):
                return web.Response(
                    status=413,
                    text=json.dumps({"error": "è¯·æ±‚ä½“è¿‡å¤§ï¼Œè¯·å‡å°è¾“å…¥æ•°æ®å¤§å°æˆ–åˆ†æ‰¹å¤„ç†"})
                )
            
            # æ ¹æ®è·¯å¾„è¯†åˆ«è®¤è¯ç±»å‹
            auth_type = self.detect_auth_type_from_path(path)
            
            # å‡†å¤‡è®¤è¯å¤´
            forward_headers = self.prepare_auth_headers(headers, auth_type)
            
            # æ„å»ºç›®æ ‡URL
            target_url = self.get_target_url(domain, path)
            
            # åˆ¤æ–­æ˜¯å¦ä¸ºæµå¼è¯·æ±‚
            is_stream = request_data.get("stream", False)
            model = request_data.get("model", "unknown")
            
            await self.async_logger.info(
                f"ğŸ“¡ åŠ¨æ€ä»£ç†è¯·æ±‚: {domain}{path}, è®¤è¯ç±»å‹: {auth_type}, æµå¼: {is_stream}, æ¨¡å‹: {model}"
            )
            
            # å‘é€è¯·æ±‚
            async with self.http_session.post(
                target_url,
                headers=forward_headers,
                json=request_data
            ) as resp:
                if is_stream:
                    return await self._handle_stream_response(resp, request, auth_type, model, request_data)
                else:
                    return await self._handle_non_stream_response(resp, auth_type, model, request_data)
        
        except json.JSONDecodeError:
            await self.async_logger.error("âŒ æ— æ•ˆçš„è¯·æ±‚æ•°æ®æ ¼å¼")
            return web.Response(status=400, text=json.dumps({"error": "æ— æ•ˆçš„è¯·æ±‚æ•°æ®æ ¼å¼"}))
        except Exception as e:
            await self.async_logger.error(f"å¤„ç†åŠ¨æ€ä»£ç†è¯·æ±‚æ—¶å‘ç”Ÿé”™è¯¯: {e}\n{traceback.format_exc()}")
            return web.Response(status=500, text=json.dumps({"error": "æœåŠ¡å™¨å†…éƒ¨é”™è¯¯"}))
    
    async def _validate_request_size(self, request_data: Dict[str, Any]) -> bool:
        """éªŒè¯è¯·æ±‚ä½“å¤§å°"""
        messages = request_data.get("messages", [])
        total_chars = sum(len(str(msg)) for msg in messages)
        max_chars = 8000000
        
        if total_chars > max_chars:
            await self.async_logger.warning(
                f"âŒ è¯·æ±‚ä½“è¿‡å¤§: {total_chars} å­—ç¬¦ï¼Œè¶…è¿‡é™åˆ¶ {max_chars} å­—ç¬¦"
            )
            return False
        return True
    
    async def _handle_stream_response(self, resp: aiohttp.ClientResponse, request: web.Request,
                                    auth_type: str, model: str, request_data: Dict[str, Any]) -> web.StreamResponse:
        """å¤„ç†æµå¼å“åº”"""
        response = web.StreamResponse(
            status=resp.status,
            headers={'Content-Type': 'text/event-stream', 'Cache-Control': 'no-cache'}
        )
        await response.prepare(request)
        
        complete_response = ""
        complete_reasoning = ""
        response_id = None
        
        try:
            async for line in resp.content:
                line_str = line.decode('utf-8').strip()
                if line_str:
                    await response.write(line.rstrip() + b'\n')
                    
                    # è§£æå“åº”å†…å®¹
                    if auth_type == "anthropic":
                        complete_response, response_id, _ = self._parse_anthropic_stream_chunk(
                            line_str, complete_response, response_id
                        )
                    else:
                        complete_response, response_id, complete_reasoning = self._parse_openai_stream_chunk(
                            line_str, complete_response, response_id
                        )
        
        except Exception as e:
            await self.async_logger.error(f"æµå¼å“åº”å¤„ç†é”™è¯¯: {e}")
        
        finally:
            # ä¿å­˜å¯¹è¯
            if response_id and complete_response:
                await self._queue_conversation(response_id, model, {
                    'request': request_data,
                    'response': complete_response,
                    'reasoning': complete_reasoning
                })
        
        return response
    
    async def _handle_non_stream_response(self, resp: aiohttp.ClientResponse,
                                        auth_type: str, model: str, request_data: Dict[str, Any]) -> web.Response:
        """å¤„ç†éæµå¼å“åº”"""
        response_text = await resp.text()
        
        try:
            response_json = json.loads(response_text)
            
            # è§£æå“åº”å†…å®¹
            if auth_type == "anthropic":
                complete_response = self._parse_anthropic_final_response(response_json)
            else:
                complete_response = self._parse_openai_final_response(response_json)
            
            # ä¿å­˜å¯¹è¯
            response_id = response_json.get('id', str(uuid.uuid4()))
            if complete_response:
                await self._queue_conversation(response_id, model, {
                    'request': request_data,
                    'response': complete_response,
                    'reasoning': ''
                })
        
        except Exception as e:
            await self.async_logger.error(f"è§£æå“åº”æ—¶å‘ç”Ÿé”™è¯¯: {e}")
        
        return web.Response(
            status=resp.status,
            text=response_text,
            headers={'Content-Type': 'application/json'}
        )
    
    def _parse_openai_stream_chunk(self, line_str: str, complete_response: str, response_id: Optional[str]):
        """è§£æOpenAIæµå¼å“åº”å—"""
        complete_reasoning = ""
        
        if line_str.startswith("data: "):
            if line_str.strip() == "data: [DONE]":
                return complete_response, response_id, complete_reasoning
            
            try:
                json_data = line_str[6:].strip()
                if json_data:
                    json_chunk = json.loads(json_data)
                    if "id" in json_chunk and not response_id:
                        response_id = json_chunk["id"]
                    if "choices" in json_chunk and json_chunk["choices"]:
                        delta = json_chunk["choices"][0].get("delta", {})
                        reasoning = delta.get("reasoning_content")
                        if reasoning is not None:
                            complete_reasoning += reasoning
                        content = delta.get("content")
                        if content is not None:
                            complete_response += content
            except json.JSONDecodeError:
                pass
            except Exception:
                pass
        
        return complete_response, response_id, complete_reasoning
    
    def _parse_anthropic_stream_chunk(self, line_str: str, complete_response: str, response_id: Optional[str]):
        """è§£æAnthropicæµå¼å“åº”å—"""
        if line_str.startswith("data: "):
            if line_str.strip() == "data: [DONE]":
                return complete_response, response_id, ""
            
            try:
                json_chunk = json.loads(line_str[6:])
                
                if json_chunk.get("type") == "message_start" and "message" in json_chunk:
                    message = json_chunk["message"]
                    if "id" in message and not response_id:
                        response_id = message["id"]
                
                elif json_chunk.get("type") == "content_block_delta":
                    delta = json_chunk.get("delta", {})
                    if delta.get("type") == "text_delta":
                        text = delta.get("text", "")
                        complete_response += text
                        
            except json.JSONDecodeError:
                pass
        
        return complete_response, response_id, ""
    
    def _parse_openai_final_response(self, response_json: Dict[str, Any]) -> str:
        """è§£æOpenAIæœ€ç»ˆå“åº”å†…å®¹"""
        if "choices" in response_json and response_json["choices"]:
            choice = response_json["choices"][0]
            if isinstance(choice, dict) and "message" in choice and isinstance(choice["message"], dict):
                reasoning_content = choice["message"].get("reasoning_content", "")
                response_content = choice["message"].get("content", "")
                return f"<think>\n{reasoning_content}\n</think>\n\n\n{response_content}" if reasoning_content else response_content
        return ""
    
    def _parse_anthropic_final_response(self, response_json: Dict[str, Any]) -> str:
        """è§£æAnthropicæœ€ç»ˆå“åº”å†…å®¹"""
        content_list = response_json.get("content", [])
        response_content = ""
        
        if isinstance(content_list, list) and content_list:
            for content_item in content_list:
                if isinstance(content_item, dict):
                    if content_item.get("type") == "text":
                        response_content += content_item.get("text", "")
        
        return response_content
    
    async def _queue_conversation(self, id: str, model: str, conversation: dict):
        """å°†å¯¹è¯åŠ å…¥é˜Ÿåˆ—ç­‰å¾…æ‰¹é‡ä¿å­˜"""
        try:
            conversation_data = {
                'id': id,
                'model': model,
                'conversation': conversation,
                'timestamp': time.time()
            }
            await self.conversation_queue.put(conversation_data)
        except Exception as e:
            await self.async_logger.error(f"åŠ å…¥å¯¹è¯é˜Ÿåˆ—å¤±è´¥: {e}")
    
    async def _batch_save_conversations(self):
        """æ‰¹é‡ä¿å­˜å¯¹è¯"""
        batch = []
        last_save_time = time.time()
        
        while True:
            try:
                # ç­‰å¾…æ–°çš„å¯¹è¯æ•°æ®æˆ–è¶…æ—¶
                try:
                    conversation_data = await asyncio.wait_for(
                        self.conversation_queue.get(), 
                        timeout=self.batch_timeout
                    )
                    batch.append(conversation_data)
                except asyncio.TimeoutError:
                    pass
                
                current_time = time.time()
                
                # æ£€æŸ¥æ˜¯å¦éœ€è¦ä¿å­˜æ‰¹æ¬¡
                should_save = (
                    len(batch) >= self.batch_size or
                    (batch and current_time - last_save_time >= self.batch_timeout)
                )
                
                if should_save and batch:
                    await self._save_batch(batch)
                    batch = []
                    last_save_time = current_time
                    
            except Exception as e:
                await self.async_logger.error(f"æ‰¹é‡ä¿å­˜å¯¹è¯æ—¶å‘ç”Ÿé”™è¯¯: {e}")
                await asyncio.sleep(1)
    
    async def _save_batch(self, batch):
        """ä¿å­˜ä¸€æ‰¹å¯¹è¯"""
        try:
            for conversation_data in batch:
                # æ ¼å¼åŒ–ä¸ºShareGPTæ ¼å¼
                sharegpt_data = format_to_sharegpt(
                    conversation_data['conversation']['request'],
                    conversation_data['conversation']['response'],
                    conversation_data['conversation'].get('reasoning', '')
                )
                
                # ä¿å­˜åˆ°æ•°æ®åº“
                await save_conversation_async(
                    conversation_data['id'],
                    conversation_data['model'],
                    json.dumps(sharegpt_data, ensure_ascii=False)
                )
            
            await self.async_logger.info(f"âœ… æˆåŠŸä¿å­˜ {len(batch)} æ¡å¯¹è¯")
            
        except Exception as e:
            await self.async_logger.error(f"ä¿å­˜å¯¹è¯æ‰¹æ¬¡å¤±è´¥: {e}")
    
    async def handle_health_check(self, request: web.Request) -> web.Response:
        """å¥åº·æ£€æŸ¥ç«¯ç‚¹"""
        return web.Response(
            status=200,
            text=json.dumps({
                "status": "healthy",
                "service": "dynamic-proxy",
                "timestamp": time.time()
            }),
            headers={'Content-Type': 'application/json'}
        )

if __name__ == "__main__":
    args = parse_args()
    proxy = DynamicProxyEndpoint(port=args.port)
    try:
        web.run_app(proxy.app, host="0.0.0.0", port=args.port)
    except Exception as e:
        logger.error(f"å¯åŠ¨æœåŠ¡å™¨æ—¶å‘ç”Ÿè‡´å‘½é”™è¯¯: {e}", exc_info=True)
    finally:
        logger.info("æœåŠ¡å™¨å·²å…³é—­")