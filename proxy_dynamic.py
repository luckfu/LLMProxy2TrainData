import json
import logging
import time
import asyncio
import uuid
from aiohttp import web
import aiohttp
import argparse
from typing import Dict, Any, Optional
import traceback

# æµå¼æ—¥å¿—é‡‡æ ·é¢‘ç‡ï¼ˆæ¯æ”¶åˆ° N æ¡å¢é‡æ‰“å°ä¸€æ¬¡è°ƒè¯•æ—¥å¿—ï¼‰
STREAM_DEBUG_SAMPLE_N = 50


from utils import format_to_sharegpt, init_async_logger, get_async_logger, init_db_path, get_db_connection, save_conversation_async
import re
from aiohttp.web_middlewares import middleware



import os

# ç©ºå¼‚æ­¥æ—¥å¿—å™¨ï¼Œé¿å…åˆå§‹åŒ–å‰çš„ None æ–¹æ³•è°ƒç”¨
class NullAsyncLogger:
    async def debug(self, msg: str):
        pass
    async def info(self, msg: str):
        pass
    async def warning(self, msg: str):
        pass
    async def error(self, msg: str):
        pass

# â€”â€”â€” è§’è‰²è§„èŒƒåŒ–ï¼ˆå…¥åº“è½»é‡çº æ­£ï¼‰ â€”â€”â€”
def looks_like_ai_reply(text: str) -> bool:
    """å¯å‘å¼åˆ¤æ–­æ–‡æœ¬æ›´åƒ AI å›ç­”è€Œéç”¨æˆ·æé—®ï¼šé•¿æ–‡æœ¬/Markdown/æ€ç»´æ ‡ç­¾/ä½é—®å¥æ¯”ç‡"""
    try:
        s = text if isinstance(text, str) else str(text)
    except Exception:
        s = ""
    length = len(s)
    score = 0
    if length >= 400:
        score += 1
    if ("###" in s) or ("**" in s) or ("<think>" in s):
        score += 1
    q_ratio = s.count("?") / max(1, length)
    if q_ratio < 0.002:
        score += 1
    return score >= 2

def normalize_roles(messages: list) -> tuple[list, bool]:
    """
    ä¿®å¤â€œè¿ç»­ä¸¤ä¸ª userâ€çš„æ˜æ˜¾å¼‚å¸¸ï¼š
    - è‹¥åä¸€ä¸ªæ›´åƒ AI å›ç­”ï¼Œåˆ™æ”¹ä¸º assistantï¼Œå¹¶åŠ  _normalized_role å®¡è®¡æ ‡è®°
    è¿”å› (ä¿®å¤åçš„æ¶ˆæ¯åˆ—è¡¨, æ˜¯å¦å‘ç”Ÿä¿®å¤)
    """
    if not isinstance(messages, list):
        return [], False
    fixed = []
    prev_role = None
    changed = False
    for m in messages:
        if not isinstance(m, dict):
            fixed.append(m)
            prev_role = None
            continue
        role = m.get("role")
        content = m.get("content", "")
        if role == "user" and prev_role == "user" and looks_like_ai_reply(content):
            nm = dict(m)
            nm["role"] = "assistant"
            nm["_normalized_role"] = "assistant"
            fixed.append(nm)
            prev_role = "assistant"
            changed = True
            continue
        fixed.append(m)
        prev_role = role
    return fixed, changed

# è‡ªå®šä¹‰æ—¥å¿—è¿‡æ»¤å™¨ï¼Œå±è”½æ¢é’ˆè¯·æ±‚çš„æ—¥å¿—
class ProbeRequestFilter(logging.Filter):
    """è¿‡æ»¤æ¢é’ˆè¯·æ±‚çš„æ—¥å¿—è®°å½•"""
    
    def __init__(self, config_file: str = None):
        super().__init__()
        
        # é»˜è®¤æ¢é’ˆè¯·æ±‚çš„ç‰¹å¾æ¨¡å¼
        default_patterns = []
        
        # é»˜è®¤æ¢é’ˆIPåœ°å€æ¨¡å¼ï¼ˆä½¿ç”¨æ›´é€šç”¨çš„æ¨¡å¼ï¼‰
        default_probe_ips = []
        
        # å°è¯•ä»é…ç½®æ–‡ä»¶åŠ è½½è‡ªå®šä¹‰æ¨¡å¼
        self.probe_patterns = default_patterns.copy()
        self.probe_ip_patterns = default_probe_ips.copy()
        
        if config_file:
            self._load_config(config_file)
        
        # ç¼–è¯‘æ­£åˆ™è¡¨è¾¾å¼ä»¥æé«˜æ€§èƒ½
        all_patterns = self.probe_patterns + self.probe_ip_patterns
        self.compiled_patterns = [re.compile(pattern) for pattern in all_patterns]
    
    def _load_config(self, config_file: str):
        """ä»é…ç½®æ–‡ä»¶åŠ è½½è‡ªå®šä¹‰è¿‡æ»¤æ¨¡å¼"""
        try:
            import json
            import os
            if os.path.exists(config_file):
                with open(config_file, 'r', encoding='utf-8') as f:
                    config = json.load(f)
                    
                # åŠ è½½è‡ªå®šä¹‰æ¢é’ˆæ¨¡å¼
                if 'probe_filter' in config:
                    filter_config = config['probe_filter']
                    
                    # ç›´æ¥æ›¿æ¢ï¼šè‹¥æä¾› patterns / ip_patternsï¼Œåˆ™è¦†ç›–é»˜è®¤
                    if 'patterns' in filter_config and isinstance(filter_config['patterns'], list):
                        self.probe_patterns = filter_config['patterns']
                    if 'ip_patterns' in filter_config and isinstance(filter_config['ip_patterns'], list):
                        self.probe_ip_patterns = filter_config['ip_patterns']
                    
                    # å…¼å®¹ï¼šè¿½åŠ è‡ªå®šä¹‰æ¨¡å¼
                    if 'custom_patterns' in filter_config:
                        self.probe_patterns.extend(filter_config['custom_patterns'])
                    
                    # å…¼å®¹ï¼šè¿½åŠ è‡ªå®šä¹‰IPæ¨¡å¼
                    if 'custom_ip_patterns' in filter_config:
                        self.probe_ip_patterns.extend(filter_config['custom_ip_patterns'])
                    
                    # å…¼å®¹ï¼šé€šè¿‡disable_*æ¸…ç©ºé»˜è®¤å¹¶é‡‡ç”¨custom_*
                    if filter_config.get('disable_default_patterns', False):
                        self.probe_patterns = filter_config.get('custom_patterns', [])
                    
                    if filter_config.get('disable_default_ip_patterns', False):
                        self.probe_ip_patterns = filter_config.get('custom_ip_patterns', [])
                        
        except Exception as e:
            # é…ç½®æ–‡ä»¶åŠ è½½å¤±è´¥æ—¶ä½¿ç”¨é»˜è®¤é…ç½®
            print(f"è­¦å‘Š: æ— æ³•åŠ è½½æ¢é’ˆè¿‡æ»¤å™¨é…ç½®æ–‡ä»¶ {config_file}: {e}")
    
    def add_pattern(self, pattern: str):
        """åŠ¨æ€æ·»åŠ è¿‡æ»¤æ¨¡å¼"""
        try:
            compiled_pattern = re.compile(pattern)
            self.compiled_patterns.append(compiled_pattern)
            self.probe_patterns.append(pattern)
        except re.error as e:
            print(f"è­¦å‘Š: æ— æ•ˆçš„æ­£åˆ™è¡¨è¾¾å¼æ¨¡å¼ '{pattern}': {e}")
    
    def remove_pattern(self, pattern: str):
        """åŠ¨æ€ç§»é™¤è¿‡æ»¤æ¨¡å¼"""
        if pattern in self.probe_patterns:
            self.probe_patterns.remove(pattern)
            # é‡æ–°ç¼–è¯‘æ‰€æœ‰æ¨¡å¼
            all_patterns = self.probe_patterns + self.probe_ip_patterns
            self.compiled_patterns = [re.compile(p) for p in all_patterns]
    
    def filter(self, record):
        """è¿‡æ»¤æ—¥å¿—è®°å½•"""
        message = record.getMessage()
        
        # æ£€æŸ¥æ˜¯å¦åŒ¹é…ä»»ä½•æ¢é’ˆæ¨¡å¼
        for pattern in self.compiled_patterns:
            if pattern.search(message):
                return False  # è¿‡æ»¤æ‰è¿™æ¡æ—¥å¿—
        
        return True  # ä¿ç•™è¿™æ¡æ—¥å¿—

def parse_args():
    parser = argparse.ArgumentParser(description="åŠ¨æ€ä»£ç†ç«¯ç‚¹æœåŠ¡å™¨")
    parser.add_argument("--port", type=int, default=8080, help="æœåŠ¡å™¨ç«¯å£")
    parser.add_argument("--log-level", default="INFO", choices=["DEBUG", "INFO", "WARNING", "ERROR"], help="æ—¥å¿—çº§åˆ«")
    return parser.parse_args()

args = parse_args()

# é…ç½®æ—¥å¿—
logging.basicConfig(level=getattr(logging, args.log_level.upper()))
logger = logging.getLogger(__name__)

# æ¸…é™¤ç°æœ‰çš„å¤„ç†å™¨
for handler in logger.handlers[:]:
    logger.removeHandler(handler)

# åˆ›å»ºæ¢é’ˆè¿‡æ»¤å™¨
# åˆ›å»ºæ¢é’ˆè¿‡æ»¤å™¨å®ä¾‹ï¼Œå°è¯•åŠ è½½é…ç½®æ–‡ä»¶
probe_filter = ProbeRequestFilter("config.json")

# ä¸ºç›¸å…³çš„æ—¥å¿—å™¨æ·»åŠ è¿‡æ»¤å™¨
aiohttp_access_logger = logging.getLogger('aiohttp.access')
aiohttp_server_logger = logging.getLogger('aiohttp.server')
asyncio_logger = logging.getLogger('asyncio')

# ä¸ºæ¯ä¸ªæ—¥å¿—å™¨æ·»åŠ è¿‡æ»¤å™¨
for log in [aiohttp_access_logger, aiohttp_server_logger, asyncio_logger]:
    log.addFilter(probe_filter)
    # ä¹Ÿä¸ºç°æœ‰çš„å¤„ç†å™¨æ·»åŠ è¿‡æ»¤å™¨
    for handler in log.handlers:
        handler.addFilter(probe_filter)

# å…¨å±€å¼‚æ­¥å¼‚å¸¸å¤„ç†å™¨
def handle_asyncio_exception(loop, context):
    """å¤„ç†asyncioä¸­æœªæ•è·çš„å¼‚å¸¸"""
    exception = context.get('exception')
    if exception:
        # æ£€æŸ¥æ˜¯å¦æ˜¯æ¢é’ˆç›¸å…³çš„å¼‚å¸¸
        error_message = str(exception)
        probe_filter_instance = ProbeRequestFilter()
        
        # åˆ›å»ºä¸€ä¸ªæ¨¡æ‹Ÿçš„æ—¥å¿—è®°å½•æ¥æµ‹è¯•è¿‡æ»¤å™¨
        class MockRecord:
            def getMessage(self):
                return error_message
        
        mock_record = MockRecord()
        if not probe_filter_instance.filter(mock_record):
            return  # å¦‚æœæ˜¯æ¢é’ˆç›¸å…³å¼‚å¸¸ï¼Œå¿½ç•¥å®ƒ
        
        logger.error(f"æœªæ•è·çš„asyncioå¼‚å¸¸: {exception}", exc_info=exception)
    else:
        logger.error(f"æœªæ•è·çš„asyncioé”™è¯¯: {context}")

@middleware
async def probe_request_middleware(request, handler):
    """ä¸­é—´ä»¶ï¼šè¿‡æ»¤æ¢é’ˆè¯·æ±‚"""
    # è·å–å®¢æˆ·ç«¯IP
    client_ip = request.remote
    if 'X-Forwarded-For' in request.headers:
        client_ip = request.headers['X-Forwarded-For'].split(',')[0].strip()
    elif 'X-Real-IP' in request.headers:
        client_ip = request.headers['X-Real-IP']
    
    # æ£€æŸ¥æ˜¯å¦ä¸ºæ¢é’ˆè¯·æ±‚
    user_agent = request.headers.get('User-Agent', '')
    path = request.path
    method = request.method
    
    # æ¢é’ˆè¯·æ±‚ç‰¹å¾ï¼ˆå¯é…ç½®ï¼‰
    cfg = request.app.get('config', {}) if hasattr(request, 'app') else {}
    probe_cfg = cfg.get('probe_request', {}) if isinstance(cfg, dict) else {}
    path_blocklist = probe_cfg.get('path_blocklist', ['/', '/favicon.ico'])
    path_prefix_blocklist = probe_cfg.get('path_prefix_blocklist', ['/.well-known/', '/locales/'])
    ua_blocklist = probe_cfg.get('user_agent_substrings', ['CensysInspect', 'Go-http-client'])
    methods_allowed = probe_cfg.get('allowed_methods', ['GET', 'POST', 'PUT', 'DELETE', 'PATCH', 'OPTIONS'])
    ip_blocklist = probe_cfg.get('ip_blocklist', ['193.34.212.110', '185.191.127.222', '162.142.125.124', '194.62.248.69', '209.38.219.203'])
    
    probe_indicators = [
        (path in path_blocklist) or any(path.startswith(p) for p in path_prefix_blocklist),
        any(s in user_agent for s in ua_blocklist),
        method not in methods_allowed,
        client_ip in ip_blocklist
    ]
    
    if any(probe_indicators):
        # é™é»˜è¿”å›404ï¼Œä¸è®°å½•æ—¥å¿—
        return web.Response(status=404, text="Not Found")
    
    # æ­£å¸¸è¯·æ±‚ï¼Œç»§ç»­å¤„ç†
    return await handler(request)

# ========== ä»£ç å±‚å®‰å…¨ä¸­é—´ä»¶ï¼ˆHost/Method/Path/é™æµ/ä½“ç§¯/å“åº”å¤´ï¼‰==========
import re as _sec_re
from typing import Dict as _SecDict

# é»˜è®¤é…ç½®ï¼ˆå¯é€šè¿‡ config.json è¦†ç›–ï¼Œé”®è·¯å¾„è§ä¸‹ï¼‰
_DEFAULT_SECURITY_CFG = {
    "allowed_hosts": ["localhost", "127.0.0.1"],  # config.security.allowed_hosts
    "enforce_host": False,  # æ˜¯å¦å¯ç”¨ Host ç™½åå•æ ¡éªŒï¼Œé»˜è®¤å…³é—­
    "allowed_methods": ["GET", "POST", "OPTIONS"],  # config.security.allowed_methods
    "max_body_size": 1 * 1024 * 1024,  # bytes, config.security.max_body_size
    "rate": 5.0,   # æ¯IPæ¯ç§’è¡¥å……ä»¤ç‰Œæ•°ï¼Œconfig.security.rate
    "burst": 20,   # æ¡¶å®¹é‡ï¼Œconfig.security.burst
    # å¸¸è§æ‰«æè·¯å¾„ï¼ˆç»“åˆä½ çš„æ—¥å¿—ï¼‰
    "suspicious_patterns": [
        r"/\+CSCOE\+",
        r"/cgi-bin/",
        r"/web/",
        r"/doc/index\.html$",
        r"/index\.html$",
        r"/admin(?:/|$)",
        r"/manage(?:/|$)",
        r"/remote/login",
        r"/login(?:\.html|\.jsp|\.asp|\.htm|/|$)",
        r"//+",                 # å¤šé‡æ–œæ 
        r"/.*:\d+$",            # /10.1.251.232:8000
    ],
    "enforce_json": True  # POST è¯·æ±‚å¼ºåˆ¶ Content-Type: application/json
}

# ä»¤ç‰Œæ¡¶
_RATE_BUCKETS: _SecDict[str, _SecDict[str, float]] = {}

def _get_security_cfg(app) -> dict:
    cfg = (app.get("config") or {}) if hasattr(app, "get") else {}
    sec = (cfg.get("security") or {}) if isinstance(cfg, dict) else {}
    merged = dict(_DEFAULT_SECURITY_CFG)
    for k, v in sec.items():
        merged[k] = v
    return merged

@web.middleware
async def host_and_method_guard_mw(request: web.Request, handler):
    sec = _get_security_cfg(request.app)
    # Host ç™½åå•ï¼ˆä»…åœ¨å¼€å¯æ—¶ç”Ÿæ•ˆï¼‰
    if sec.get("enforce_host", False):
        host = request.headers.get("Host", "")
        hostname = host.split(":")[0].lower()
        if hostname not in set(h.lower() for h in sec.get("allowed_hosts", [])):
            return web.Response(status=403, text="Forbidden")
    # Method ç™½åå•
    if request.method not in set(sec["allowed_methods"]):
        return web.Response(status=405, text="Method Not Allowed")
    # å¯é€‰ï¼šPOST å¿…é¡»æ˜¯ JSON
    if sec.get("enforce_json", True) and request.method == "POST":
        ctype = request.headers.get("Content-Type", "")
        if "application/json" not in ctype:
            return web.Response(status=415, text="Unsupported Media Type")
    return await handler(request)

# é¢„ç¼–è¯‘æ¶æ„è·¯å¾„æ­£åˆ™
_SUSP_RE = [_sec_re.compile(p, _sec_re.I) for p in _DEFAULT_SECURITY_CFG["suspicious_patterns"]]

@web.middleware
async def path_guard_mw(request: web.Request, handler):
    sec = _get_security_cfg(request.app)
    patterns = sec.get("suspicious_patterns") or []
    # è‹¥é…ç½®è¦†ç›–äº† patternsï¼Œé‡æ–°æŒ‰é…ç½®ç¼–è¯‘ä¸€æ¬¡
    regexes = _SUSP_RE if patterns == _DEFAULT_SECURITY_CFG["suspicious_patterns"] else [
        _sec_re.compile(p, _sec_re.I) for p in patterns
    ]
    path = request.rel_url.path
    for r in regexes:
        if r.search(path):
            # å¯¹â€œè¿ç»­å¤šæ–œæ â€ç»™å‡ºæ›´å‹å¥½çš„æç¤ºï¼Œä¾¿äºç”¨æˆ·ä¿®æ­£
            if r.pattern == r"//+" and path.startswith("//"):
                err = {
                    "error": "è·¯å¾„åŒ…å«è¿ç»­æ–œæ ï¼Œè¯·æ”¹ä¸ºå•æ–œæ ",
                    "hint": "ç¤ºä¾‹ï¼š/api.openai.com/v1/chat/completions æˆ– /generativelanguage.googleapis.com/...",
                    "note": "å¦‚ç›®æ ‡åŸŸåæœªåœ¨ç™½åå•ï¼Œè¯·åœ¨ config.json çš„ allowed_domains ä¸­æ·»åŠ "
                }
                return web.Response(status=400, text=json.dumps(err, ensure_ascii=False), headers={"Content-Type": "application/json"})
            return web.Response(status=404, text="Not Found")
    return await handler(request)

def _allow_ip(ip: str, rate: float, burst: int) -> bool:
    now = time.time()
    b = _RATE_BUCKETS.get(ip)
    if b is None:
        _RATE_BUCKETS[ip] = {"tokens": burst - 1, "ts": now}
        return True
    elapsed = now - b["ts"]
    b["ts"] = now
    b["tokens"] = min(burst, b["tokens"] + elapsed * rate)
    if b["tokens"] >= 1.0:
        b["tokens"] -= 1.0
        return True
    return False

@web.middleware
async def rate_limit_mw(request: web.Request, handler):
    sec = _get_security_cfg(request.app)
    rate = float(sec.get("rate", _DEFAULT_SECURITY_CFG["rate"]))
    burst = int(sec.get("burst", _DEFAULT_SECURITY_CFG["burst"]))
    xff = request.headers.get("X-Forwarded-For", "")
    ip = (xff.split(",")[0].strip() if xff else request.remote) or "unknown"
    if not _allow_ip(ip, rate, burst):
        return web.Response(status=429, text="Too Many Requests")
    return await handler(request)

@web.middleware
async def max_body_mw(request: web.Request, handler):
    sec = _get_security_cfg(request.app)
    max_size = int(sec.get("max_body_size", _DEFAULT_SECURITY_CFG["max_body_size"]))
    cl = request.headers.get("Content-Length")
    if cl and cl.isdigit() and int(cl) > max_size:
        return web.Response(status=413, text="Payload Too Large")
    return await handler(request)

@web.middleware
async def security_headers_mw(request: web.Request, handler):
    resp = await handler(request)
    # éšåŒ¿æœåŠ¡ä¿¡æ¯ä¸æ·»åŠ å®‰å…¨å¤´
    resp.headers["Server"] = " "
    resp.headers["X-Content-Type-Options"] = "nosniff"
    resp.headers["X-Frame-Options"] = "DENY"
    resp.headers["Referrer-Policy"] = "no-referrer"
    resp.headers["Content-Security-Policy"] = "default-src 'none'; frame-ancestors 'none'; base-uri 'none'"
    return resp

class DynamicProxyEndpoint:
    """åŠ¨æ€ä»£ç†ç«¯ç‚¹ï¼Œæ— éœ€é…ç½®æ–‡ä»¶"""
    
    def _extract_messages_for_archive(self, auth_type: str, request_data: Dict[str, Any]) -> list[dict]:
        """ä»è¯·æ±‚ä½“ä¸­æŠ½å–å½’æ¡£ç”¨çš„ messagesï¼Œå…¼å®¹ Google contents ä¸ OpenAI messagesï¼›æ­£ç¡®æ˜ å°„ user/model/system"""
        msgs: list[dict] = []
        try:
            if auth_type == "google":
                # å…ˆå¤„ç† systemInstruction
                sys_inst = request_data.get("systemInstruction")
                if isinstance(sys_inst, dict):
                    sys_parts = sys_inst.get("parts", [])
                    if isinstance(sys_parts, list):
                        stexts = []
                        for sp in sys_parts:
                            if isinstance(sp, dict):
                                t = sp.get("text")
                                if isinstance(t, str) and t:
                                    stexts.append(t)
                        if stexts:
                            msgs.append({"role": "system", "content": "\n".join(stexts)})
                # å†å¤„ç† contents
                role_map = {"user": "user", "model": "assistant", "system": "system"}
                contents = request_data.get("contents")
                if isinstance(contents, list) and contents:
                    for content in contents:
                        if not isinstance(content, dict):
                            continue
                        parts = content.get("parts", [])
                        role_raw = content.get("role")
                        role = role_map.get(role_raw if isinstance(role_raw, str) else "user", "user")
                        text_parts: list[str] = []
                        if isinstance(parts, list):
                            for part in parts:
                                if isinstance(part, dict):
                                    t = part.get("text")
                                    if isinstance(t, str):
                                        text_parts.append(t)
                        if text_parts:
                            msgs.append({"role": role, "content": "\n".join(text_parts)})
                else:
                    # å›é€€ï¼šæ”¯æŒå®¢æˆ·ç«¯ç›´æ¥ä½¿ç”¨ OpenAI messages
                    om = request_data.get("messages")
                    if isinstance(om, list):
                        for m in om:
                            if isinstance(m, dict) and "role" in m:
                                role = m.get("role")
                                if role in ("user", "assistant", "system"):
                                    msgs.append({
                                        "role": role,
                                        "content": str(m.get("content", "")) if m.get("content") is not None else ""
                                    })
            else:
                om = request_data.get("messages")
                if isinstance(om, list):
                    msgs = om
        except Exception:
            # å¤±è´¥æ—¶è¿”å›ç©ºæ•°ç»„ï¼Œåç»­æ ¼å¼åŒ–å‡½æ•°ä»å¯å¤„ç†
            msgs = []
        return msgs
    
    def __init__(self, port: int = 8080):
        self.port = port

        # å…ˆåŠ è½½é…ç½®æ–‡ä»¶ï¼ˆä¾›å®‰å…¨ä¸­é—´ä»¶ä¸ client_max_size ä½¿ç”¨ï¼‰
        self.config = {}
        try:
            if os.path.exists("config.json"):
                with open("config.json", "r", encoding="utf-8") as f:
                    self.config = json.load(f)
        except Exception:
            self.config = {}

        security_cfg = (self.config.get("security") or {}) if isinstance(self.config, dict) else {}
        client_max_size = int(security_cfg.get("max_body_size", 1 * 1024 * 1024))

        # åº”ç”¨ä¸ä¸­é—´ä»¶ï¼ˆé¡ºåºï¼šå¿«é€Ÿæ‹’ç» -> é™æµ/ä½“ç§¯ -> å…¼å®¹æ—§æ¢é’ˆè¿‡æ»¤ -> å®‰å…¨å¤´ï¼‰
        self.app = web.Application(
            middlewares=[
                host_and_method_guard_mw,
                path_guard_mw,
                rate_limit_mw,
                max_body_mw,
                probe_request_middleware,
                security_headers_mw,
            ],
            client_max_size=client_max_size
        )
        # è®©ä¸­é—´ä»¶å¯è¯»å–é…ç½®
        self.app["config"] = self.config

        self.setup_routes()
        
        # æ€§èƒ½ä¼˜åŒ–ç›¸å…³
        self.http_session = None
        self.async_logger = NullAsyncLogger()
        # é¢„ç½®ä¸€ä¸ªé˜Ÿåˆ—ï¼Œå¯åŠ¨æ—¶ä¼šè¦†ç›–
        self.conversation_queue = asyncio.Queue(maxsize=1000)
        self.batch_size = 10
        self.batch_timeout = 5.0
        self.batch_save_task = None  # æ·»åŠ æ‰¹é‡ä¿å­˜ä»»åŠ¡çš„å¼•ç”¨
        
        # åŸŸåç™½åå•å’Œè®¤è¯æ˜ å°„
        # æœ€å°ç™½åå•ï¼ˆå®Œæ•´åˆ—è¡¨è¿ç§»è‡³ config.jsonï¼‰
        self.allowed_domains = {
            'generativelanguage.googleapis.com': {'auth_type': 'google', 'https': True},
            'api.openai.com': {'auth_type': 'openai', 'https': True}
        }
        
        # å…è®¸ç”¨é…ç½®è¦†ç›– allowed_domains
        try:
            cfg_domains = self.config.get("allowed_domains") if isinstance(self.config, dict) else None
            if isinstance(cfg_domains, dict):
                self.allowed_domains = cfg_domains
        except Exception:
            pass
        
        # è®¾ç½®åº”ç”¨å¯åŠ¨å’Œæ¸…ç†äº‹ä»¶
        self.app.on_startup.append(self.init_async_resources)
        self.app.on_cleanup.append(self.cleanup_resources)
    
    def setup_routes(self):
        """è®¾ç½®è·¯ç”±"""
        # æ ‡å‡†OpenAI APIç«¯ç‚¹è·¯ç”±ï¼ˆä¼˜å…ˆçº§æ›´é«˜ï¼‰
        self.app.router.add_post("/v1/chat/completions", self.handle_openai_api)
        self.app.router.add_post("/v1/completions", self.handle_openai_api)
        self.app.router.add_post("/v1/embeddings", self.handle_openai_api)
        
        # åŠ¨æ€ä»£ç†è·¯ç”±ï¼š/{domain}/{path:.*} - æ”¯æŒGETå’ŒPOSTè¯·æ±‚
        self.app.router.add_post("/{domain}/{path:.*}", self.handle_dynamic_proxy)
        self.app.router.add_get("/{domain}/{path:.*}", self.handle_dynamic_proxy)
        self.app.router.add_get("/health", self.handle_health_check)
        
    async def init_async_resources(self, app):
        """åˆå§‹åŒ–å¼‚æ­¥èµ„æº"""
        # è®¾ç½®å…¨å±€å¼‚æ­¥å¼‚å¸¸å¤„ç†å™¨
        loop = asyncio.get_event_loop()
        loop.set_exception_handler(handle_asyncio_exception)
        
        # åˆå§‹åŒ–å¼‚æ­¥æ—¥å¿—
        await asyncio.to_thread(init_async_logger, "proxy_dynamic", "proxy_dynamic.log", getattr(logging, args.log_level.upper()))
        self.async_logger = get_async_logger()
        if self.async_logger is None:
            raise ValueError("Failed to initialize async_logger")
        await self.async_logger.info("âœ… å¼‚æ­¥æ—¥å¿—åˆå§‹åŒ–å®Œæˆ")
        
        # å°†é…ç½®æ³¨å…¥appï¼Œä¾›ä¸­é—´ä»¶ç­‰ä½¿ç”¨
        self.app['config'] = getattr(self, 'config', {})
        
        # åˆå§‹åŒ–æ•°æ®åº“
        await init_db_path("interactions.db")
        await self.async_logger.info("âœ… æ•°æ®åº“åˆå§‹åŒ–å®Œæˆ")
        
        # åˆå§‹åŒ–HTTPè¿æ¥æ± 
        connector = aiohttp.TCPConnector(
            limit=100,
            limit_per_host=30,
            ttl_dns_cache=300,
            use_dns_cache=True,
            keepalive_timeout=30,
            enable_cleanup_closed=True
        )
        
        timeout = aiohttp.ClientTimeout(
            total=900,  # å¢åŠ æ€»è¶…æ—¶æ—¶é—´åˆ°15åˆ†é’Ÿ
            connect=60,  # å¢åŠ è¿æ¥è¶…æ—¶åˆ°60ç§’
            sock_connect=60,  # å¢åŠ socketè¿æ¥è¶…æ—¶åˆ°60ç§’
            sock_read=900  # å¢åŠ è¯»å–è¶…æ—¶åˆ°15åˆ†é’Ÿ
        )
        
        self.http_session = aiohttp.ClientSession(
            connector=connector,
            timeout=timeout,
            headers={'User-Agent': 'DynamicProxy/1.0'}
        )
        
        await self.async_logger.info("âœ… HTTPè¿æ¥æ± åˆå§‹åŒ–å®Œæˆ")
        
        # åˆå§‹åŒ–æ‰¹é‡å¤„ç†é˜Ÿåˆ—
        self.conversation_queue = asyncio.Queue(maxsize=1000)
        self.batch_save_task = asyncio.create_task(self._batch_save_conversations())
        await self.async_logger.info("âœ… æ‰¹é‡å¤„ç†é˜Ÿåˆ—åˆå§‹åŒ–å®Œæˆ")
        
        await self.async_logger.info("ğŸš€ åŠ¨æ€ä»£ç†æœåŠ¡å™¨å¯åŠ¨å®Œæˆ")
    
    async def cleanup_resources(self, app):
        """æ¸…ç†èµ„æº"""
        # åœæ­¢æ‰¹é‡ä¿å­˜ä»»åŠ¡å¹¶ç­‰å¾…å®Œæˆ
        if self.batch_save_task and not self.batch_save_task.done():
            self.batch_save_task.cancel()
            try:
                await self.batch_save_task
            except asyncio.CancelledError:
                pass
            
        # å¤„ç†é˜Ÿåˆ—ä¸­å‰©ä½™çš„å¯¹è¯æ•°æ®
        if self.conversation_queue and not self.conversation_queue.empty():
            remaining_conversations = []
            while not self.conversation_queue.empty():
                try:
                    conversation_data = self.conversation_queue.get_nowait()
                    remaining_conversations.append(conversation_data)
                except asyncio.QueueEmpty:
                    break
            
            # ä¿å­˜å‰©ä½™çš„å¯¹è¯æ•°æ®
            if remaining_conversations:
                await self._save_batch(remaining_conversations)
                if self.async_logger:
                    await self.async_logger.info(f"ğŸ’¾ ä¿å­˜äº† {len(remaining_conversations)} æ¡å‰©ä½™å¯¹è¯æ•°æ®")
        
        # å…³é—­HTTPä¼šè¯
        if self.http_session:
            await self.http_session.close()
            
        if self.async_logger:
            await self.async_logger.info("ğŸ”„ èµ„æºæ¸…ç†å®Œæˆ")
    
    def detect_auth_type_from_path(self, path: str) -> str:
        """æ ¹æ®è·¯å¾„æ¨¡å¼è¯†åˆ«è®¤è¯ç±»å‹"""
        # Google Gemini API è·¯å¾„æ¨¡å¼
        if "/v1beta/models/" in path and ":generateContent" in path:
            return "google"
        # Anthropic API è·¯å¾„æ¨¡å¼
        elif "/anthropic/" in path or "/v1/messages" in path:
            return "anthropic"
        # OpenAI API è·¯å¾„æ¨¡å¼
        elif "/v1/chat/completions" in path or "/chat/completions" in path:
            return "openai"
        elif "/v1/embeddings" in path:
            return "openai"
        elif "/v1/rerank" in path:
            return "openai"
        else:
            # é»˜è®¤ä½¿ç”¨openaiæ ¼å¼
            return "openai"
    
    def extract_model_from_request(self, request_data: Dict[str, Any], path: str, auth_type: str) -> str:
        """ä»è¯·æ±‚ä¸­æå–æ¨¡å‹åç§°"""
        # å¯¹äºGoogle Gemini APIï¼Œä»URLè·¯å¾„ä¸­æå–æ¨¡å‹åç§°
        if auth_type == "google" and "/v1beta/models/" in path:
            # è·¯å¾„æ ¼å¼: /v1beta/models/gemini-pro:generateContent
            # æˆ–: /v1beta/models/gemini-2.5-pro:streamGenerateContent
            import re
            match = re.search(r'/v1beta/models/([^:]+)', path)
            if match:
                return match.group(1)
        
        # å¯¹äºå…¶ä»–APIï¼Œä»è¯·æ±‚ä½“ä¸­è·å–æ¨¡å‹åç§°
        return request_data.get("model", "unknown")
    
    def prepare_auth_headers(self, request_headers: Dict[str, str], auth_type: str) -> Dict[str, str]:
        """æ ¹æ®è®¤è¯ç±»å‹å‡†å¤‡è¯·æ±‚å¤´ï¼šä¿ç•™ Authorization ä¸æ‰€æœ‰ x-* å¤´ï¼Œè¡¥å…… Content-Type"""
        forward_headers: Dict[str, str] = {"Content-Type": "application/json"}
        for k, v in request_headers.items():
            kl = k.lower()
            if kl == "authorization" or kl.startswith("x-"):
                forward_headers[k] = v
        return forward_headers
    
    def is_domain_allowed(self, domain: str) -> bool:
        """æ£€æŸ¥åŸŸåæ˜¯å¦åœ¨ç™½åå•ä¸­"""
        return domain in self.allowed_domains
    
    def get_target_url(self, domain: str, path: str) -> str:
        """æ„å»ºç›®æ ‡URL"""
        domain_config = self.allowed_domains.get(domain, {'https': True})
        protocol = 'https' if domain_config.get('https', True) else 'http'
        # ä¿ç•™åŸå§‹è·¯å¾„å’ŒæŸ¥è¯¢å‚æ•°
        return f"{protocol}://{domain}{path}"
    
    async def handle_openai_api(self, request: web.Request) -> web.StreamResponse:
        """å¤„ç†æ ‡å‡†OpenAI APIç«¯ç‚¹è¯·æ±‚"""
        try:
            # è·å–è¯·æ±‚æ•°æ®
            headers = dict(request.headers)
            request_data = await request.json()
            
            # è°ƒè¯•ï¼šæ‰“å°å®¢æˆ·ç«¯å‘é€çš„æ¶ˆæ¯
            await self.async_logger.info(f"ğŸ” OpenAI API - å®¢æˆ·ç«¯è¯·æ±‚æ•°æ®: {json.dumps(request_data, ensure_ascii=False, indent=2)}")
            
            # è¯·æ±‚ä½“å¤§å°æ£€æŸ¥
            if not await self._validate_request_size(request_data):
                return web.Response(
                    status=413,
                    text=json.dumps({"error": "è¯·æ±‚ä½“è¿‡å¤§ï¼Œè¯·å‡å°è¾“å…¥æ•°æ®å¤§å°æˆ–åˆ†æ‰¹å¤„ç†"})
                )
            
            # ä»è¯·æ±‚å¤´ä¸­è·å–Authorizationï¼Œç¡®å®šç›®æ ‡åŸŸå
            auth_header = headers.get('Authorization', '')
            if not auth_header.startswith('Bearer '):
                return web.Response(
                    status=401,
                    text=json.dumps({"error": "ç¼ºå°‘æœ‰æ•ˆçš„Authorizationå¤´"})
                )
            
            # æ ¹æ®API Keyæˆ–æ¨¡å‹åç§°ç¡®å®šç›®æ ‡åŸŸå
            # è¿™é‡Œä½¿ç”¨é»˜è®¤çš„Google Gemini APIé…ç½®
            target_domain = 'generativelanguage.googleapis.com'
            auth_type = 'google'
            
            # æ„å»ºç›®æ ‡URL
            path = str(request.url.path)
            if request.query_string:
                path += '?' + request.query_string
            
            # å¯¹äºGoogle APIï¼Œéœ€è¦è½¬æ¢è·¯å¾„æ ¼å¼
            if auth_type == 'google':
                model = request_data.get('model', 'gemini-2.0-flash-exp')
                path = f"/v1beta/models/{model}:generateContent"
                if request_data.get('stream', False):
                    path = f"/v1beta/models/{model}:streamGenerateContent"
            
            target_url = self.get_target_url(target_domain, path)
            
            # å‡†å¤‡è®¤è¯å¤´
            auth_headers = self.prepare_auth_headers(headers, auth_type)
            
            # è½¬æ¢è¯·æ±‚æ•°æ®æ ¼å¼
            if auth_type == 'google':
                # è½¬æ¢OpenAIæ ¼å¼åˆ°Googleæ ¼å¼
                google_request = self._convert_openai_to_google(request_data)
                request_data = google_request
            
            # å‘é€è¯·æ±‚åˆ°ç›®æ ‡API
            async with self.http_session.post(
                target_url,
                headers=auth_headers,
                json=request_data,
                timeout=aiohttp.ClientTimeout(total=120)
            ) as resp:
                
                # æ£€æŸ¥æ˜¯å¦ä¸ºæµå¼å“åº”
                is_stream = request_data.get('stream', False) or 'text/event-stream' in resp.headers.get('content-type', '')
                
                if is_stream:
                    return await self._handle_stream_response(resp, request, auth_type, 
                                                            request_data.get('model', 'unknown'), request_data)
                else:
                    return await self._handle_non_stream_response(resp, auth_type, 
                                                                request_data.get('model', 'unknown'), request_data)
                    
        except Exception as e:
            await self.async_logger.error(f"âŒ OpenAI APIå¤„ç†å¼‚å¸¸: {e}", exc_info=True)
            return web.Response(
                status=500,
                text=json.dumps({"error": f"æœåŠ¡å™¨å†…éƒ¨é”™è¯¯: {str(e)}"})
            )
    
    def _convert_openai_to_google(self, openai_request: Dict[str, Any]) -> Dict[str, Any]:
        """å°†OpenAIæ ¼å¼è¯·æ±‚è½¬æ¢ä¸ºGoogleæ ¼å¼"""
        messages = openai_request.get('messages', [])
        
        # è½¬æ¢æ¶ˆæ¯æ ¼å¼
        contents = []
        for msg in messages:
            role = msg.get('role', 'user')
            content = msg.get('content', '')
            
            if role == 'system':
                # Google APIä¸­systemæ¶ˆæ¯éœ€è¦ç‰¹æ®Šå¤„ç†
                contents.append({
                    "role": "user",
                    "parts": [{"text": f"System: {content}"}]
                })
            elif role == 'user':
                contents.append({
                    "role": "user", 
                    "parts": [{"text": content}]
                })
            elif role == 'assistant':
                contents.append({
                    "role": "model",
                    "parts": [{"text": content}]
                })
        
        # æ„å»ºGoogle APIè¯·æ±‚
        google_request = {
            "contents": contents,
            "generationConfig": {
                "temperature": openai_request.get('temperature', 0.7),
                "maxOutputTokens": openai_request.get('max_tokens', 2048),
                "topP": openai_request.get('top_p', 1.0),
            }
        }
        
        return google_request

    async def handle_dynamic_proxy(self, request: web.Request) -> web.StreamResponse:
        """å¤„ç†åŠ¨æ€ä»£ç†è¯·æ±‚"""
        try:
            # è§£æURLå‚æ•°
            domain = request.match_info['domain']
            path = '/' + request.match_info['path']
            
            # ä¿ç•™æŸ¥è¯¢å‚æ•°
            if request.query_string:
                path += '?' + request.query_string
            
            # å®‰å…¨æ£€æŸ¥ï¼šéªŒè¯åŸŸåç™½åå•
            if not self.is_domain_allowed(domain):
                await self.async_logger.warning(f"âŒ ä¸å…è®¸çš„åŸŸå: {domain}")
                return web.Response(
                    status=403,
                    text=json.dumps({"error": f"åŸŸå {domain} ä¸åœ¨å…è®¸åˆ—è¡¨ä¸­"})
                )
            
            # è·å–è¯·æ±‚æ•°æ®
            headers = dict(request.headers)
            
            # å¤„ç†GETè¯·æ±‚ï¼ˆæ— è¯·æ±‚ä½“ï¼‰å’ŒPOSTè¯·æ±‚ï¼ˆæœ‰è¯·æ±‚ä½“ï¼‰
            if request.method == 'GET':
                request_data = {}
                await self.async_logger.debug(f"ğŸ” è°ƒè¯• - GETè¯·æ±‚: {request.method} {path}")
            else:
                request_data = await request.json()
                # è°ƒè¯•ï¼šæ‰“å°å®¢æˆ·ç«¯å‘é€çš„æ¶ˆæ¯
                await self.async_logger.debug(f"ğŸ” è°ƒè¯• - å®¢æˆ·ç«¯è¯·æ±‚æ•°æ®: {json.dumps(request_data, ensure_ascii=False, indent=2)}")
                
                # è¯·æ±‚ä½“å¤§å°æ£€æŸ¥ï¼ˆä»…å¯¹POSTè¯·æ±‚ï¼‰
                if not await self._validate_request_size(request_data):
                    return web.Response(
                        status=413,
                        text=json.dumps({"error": "è¯·æ±‚ä½“è¿‡å¤§ï¼Œè¯·å‡å°è¾“å…¥æ•°æ®å¤§å°æˆ–åˆ†æ‰¹å¤„ç†"})
                    )
            
            # æ ¹æ®åŸŸåé…ç½®æˆ–è·¯å¾„è¯†åˆ«è®¤è¯ç±»å‹
            domain_config = self.allowed_domains.get(domain, {})
            if 'auth_type' in domain_config:
                # ä¼˜å…ˆä½¿ç”¨åŸŸåé…ç½®çš„è®¤è¯ç±»å‹
                auth_type = domain_config['auth_type']
            else:
                # å›é€€åˆ°è·¯å¾„æ¨¡å¼è¯†åˆ«
                auth_type = self.detect_auth_type_from_path(path)
            
            # å‡†å¤‡è®¤è¯å¤´
            forward_headers = self.prepare_auth_headers(headers, auth_type)
            
            # æ„å»ºç›®æ ‡URL
            target_url = self.get_target_url(domain, path)
            
            # åˆ¤æ–­æ˜¯å¦ä¸ºæµå¼è¯·æ±‚
            is_stream = request_data.get("stream", False)
            
            # Google APIç‰¹æ®Šå¤„ç†ï¼šæ£€æŸ¥URLä¸­æ˜¯å¦åŒ…å«streamGenerateContent
            if auth_type == "google" and "streamGenerateContent" in path:
                is_stream = True
                await self.async_logger.debug(f"ğŸ” è°ƒè¯• - Googleæµå¼è¯·æ±‚æ£€æµ‹: URLåŒ…å«streamGenerateContentï¼Œè®¾ç½®ä¸ºæµå¼")
            
            # è§£ææ¨¡å‹åç§°
            model = self.extract_model_from_request(request_data, path, auth_type)
            
            await self.async_logger.info(
                f"ğŸ“¡ åŠ¨æ€ä»£ç†è¯·æ±‚: {domain}{path}, è®¤è¯ç±»å‹: {auth_type}, æµå¼: {is_stream}, æ¨¡å‹: {model}"
            )
            
            # å‘é€è¯·æ±‚ï¼ˆå¸¦é‡è¯•æœºåˆ¶ï¼‰
            max_retries = 3
            retry_delay = 1  # åˆå§‹é‡è¯•å»¶è¿Ÿï¼ˆç§’ï¼‰
            
            for attempt in range(max_retries):
                try:
                    # æ ¹æ®è¯·æ±‚æ–¹æ³•é€‰æ‹©åˆé€‚çš„HTTPæ–¹æ³•
                    if request.method == 'GET':
                        async with self.http_session.get(
                            target_url,
                            headers=forward_headers
                        ) as resp:
                            # GETè¯·æ±‚é€šå¸¸ä¸æ˜¯æµå¼çš„ï¼Œç›´æ¥è¿”å›å“åº”
                            return await self._handle_non_stream_response(resp, auth_type, model, request_data)
                    else:
                        async with self.http_session.post(
                            target_url,
                            headers=forward_headers,
                            json=request_data
                        ) as resp:
                            if is_stream:
                                return await self._handle_stream_response(resp, request, auth_type, model, request_data)
                            else:
                                return await self._handle_non_stream_response(resp, auth_type, model, request_data)
                
                except (aiohttp.ClientError, asyncio.TimeoutError, TimeoutError) as e:
                    if attempt < max_retries - 1:  # ä¸æ˜¯æœ€åä¸€æ¬¡å°è¯•
                        await self.async_logger.warning(f"ğŸ”„ è¿æ¥å¤±è´¥ï¼Œç¬¬{attempt + 1}æ¬¡é‡è¯• (å…±{max_retries}æ¬¡): {str(e)}")
                        await asyncio.sleep(retry_delay)
                        retry_delay *= 2  # æŒ‡æ•°é€€é¿
                    else:
                        await self.async_logger.error(f"âŒ è¿æ¥å¤±è´¥ï¼Œå·²è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°: {str(e)}")
                        return web.Response(status=500, text=json.dumps({"error": "è¿æ¥è¶…æ—¶ï¼Œè¯·ç¨åé‡è¯•"}))
        
        except json.JSONDecodeError:
            await self.async_logger.error("âŒ æ— æ•ˆçš„è¯·æ±‚æ•°æ®æ ¼å¼")
            return web.Response(status=400, text=json.dumps({"error": "æ— æ•ˆçš„è¯·æ±‚æ•°æ®æ ¼å¼"}))
        except Exception as e:
            await self.async_logger.error(f"å¤„ç†åŠ¨æ€ä»£ç†è¯·æ±‚æ—¶å‘ç”Ÿé”™è¯¯: {e}\n{traceback.format_exc()}")
            return web.Response(status=500, text=json.dumps({"error": "æœåŠ¡å™¨å†…éƒ¨é”™è¯¯"}))
    
    async def _validate_request_size(self, request_data: Dict[str, Any]) -> bool:
        """éªŒè¯è¯·æ±‚ä½“å¤§å°ï¼ˆå…¼å®¹ OpenAI messages ä¸ Google contents.partsï¼‰"""
        max_chars = 8000000
        total_chars = 0

        # OpenAI/Anthropic é£æ ¼
        messages = request_data.get("messages", [])
        if isinstance(messages, list) and messages:
            try:
                for msg in messages:
                    if isinstance(msg, dict):
                        # åªç»Ÿè®¡ä¸»è¦æ–‡æœ¬
                        total_chars += len(str(msg.get("content", "")))
                    else:
                        total_chars += len(str(msg))
            except Exception:
                total_chars += len(str(messages))

        # Google Gemini é£æ ¼
        if total_chars == 0:
            contents = request_data.get("contents", [])
            if isinstance(contents, list) and contents:
                try:
                    for content in contents:
                        if isinstance(content, dict):
                            parts = content.get("parts", [])
                            if isinstance(parts, list):
                                for part in parts:
                                    if isinstance(part, dict):
                                        t = part.get("text")
                                        if isinstance(t, str):
                                            total_chars += len(t)
                except Exception:
                    total_chars += len(str(contents))

        if total_chars > max_chars:
            await self.async_logger.warning(
                f"âŒ è¯·æ±‚ä½“è¿‡å¤§: {total_chars} å­—ç¬¦ï¼Œè¶…è¿‡é™åˆ¶ {max_chars} å­—ç¬¦"
            )
            return False
        return True
    
    async def _handle_stream_response(self, resp: aiohttp.ClientResponse, request: web.Request,
                                    auth_type: str, model: str, request_data: Dict[str, Any]) -> web.StreamResponse:
        """å¤„ç†æµå¼å“åº”"""
        response = web.StreamResponse(
            status=resp.status,
            headers={'Content-Type': 'text/event-stream', 'Cache-Control': 'no-cache'}
        )
        await response.prepare(request)
        
        complete_response = ""
        complete_reasoning = ""
        response_id = None
        # Anthropic å·¥å…·æµå¼è§£æçŠ¶æ€
        anthropic_tool_current = None
        anthropic_tool_calls = []
        anthropic_stop_reason = None
        # é™å™ªï¼šé«˜é¢‘ç‰‡æ®µæ—¥å¿—é‡‡æ ·
        stream_debug_counter = 0
        
        try:
            async for line in resp.content:
                # åŸæ ·é€ä¼ ä¸Šæ¸¸æ•°æ®ï¼Œä¿ç•™æ¢è¡Œä¸ç©ºè¡Œï¼ˆå¢åŠ å®¢æˆ·ç«¯æ–­å¼€é˜²æŠ¤ï¼‰
                transport = getattr(request, "transport", None)
                if transport is None or transport.is_closing():
                    await self.async_logger.info("ğŸ”Œ å®¢æˆ·ç«¯è¿æ¥å·²å…³é—­ï¼Œåœæ­¢ç»§ç»­å†™å…¥æµå¼æ•°æ®")
                    break
                try:
                    await response.write(line)
                  
                except (ConnectionResetError, BrokenPipeError, aiohttp.ClientConnectionResetError, asyncio.CancelledError):
                    await self.async_logger.info("ğŸ”Œ å®¢æˆ·ç«¯æ–­å¼€è¿æ¥ï¼Œåœæ­¢å†™å…¥")
                    break
                # å…¶ä»–å¼‚å¸¸äº¤ç”±å¤–å±‚æ•è·
                 
                # ä¸ºæ—¥å¿—ä¸è§£æå•ç‹¬æ„é€ å­—ç¬¦ä¸²ï¼Œä¸å½±å“é€ä¼ 
                try:
                    line_text = line.decode('utf-8', errors='ignore')
                except Exception:
                    line_text = ''
                line_str = line_text.strip()
                
                if line_str:
                    # è°ƒè¯•ï¼šé«˜é¢‘é‡‡æ ·æ‰“å°ï¼Œé™ä½å™ªå£°
                    stream_debug_counter += 1
                    if stream_debug_counter % STREAM_DEBUG_SAMPLE_N == 1:
                        await self.async_logger.debug(f"ğŸ” è°ƒè¯• - æ¥æ”¶åˆ°æµå¼æ•°æ®: {line_str[:200]}...")
                    
                    # è§£æå“åº”å†…å®¹
                    if auth_type == "anthropic":
                        # ç›´æ¥è§£æ JSON äº‹ä»¶ï¼Œæ•è·å·¥å…·è°ƒç”¨
                        if line_str.startswith("data: "):
                            data_str = line_str[6:].strip()
                            try:
                                evt = json.loads(data_str)
                                etype = evt.get("type")
                                # æ¶ˆæ¯å¼€å§‹ï¼Œè®°å½• id
                                if etype == "message_start" and "message" in evt and not response_id:
                                    mid = evt["message"].get("id")
                                    if mid:
                                        response_id = mid
                                # æ–‡æœ¬å¢é‡
                                elif etype == "content_block_delta":
                                    delta = evt.get("delta", {})
                                    if delta.get("type") == "text_delta":
                                        text = delta.get("text", "")
                                        if isinstance(text, str):
                                            complete_response += text
                                    # å·¥å…·è¾“å…¥ JSON å¢é‡
                                    elif delta.get("type") == "input_json_delta":
                                        pj = delta.get("partial_json", "")
                                        if anthropic_tool_current is not None and isinstance(pj, str):
                                            anthropic_tool_current["input_json"] += pj
                                # å·¥å…·å—å¼€å§‹
                                elif etype == "content_block_start":
                                    block = evt.get("content_block", {})
                                    if block.get("type") == "tool_use":
                                        anthropic_tool_current = {
                                            "id": block.get("id"),
                                            "name": block.get("name"),
                                            "input_json": ""
                                        }
                                # å·¥å…·å—ç»“æŸï¼Œç»„è£…ä¸€æ¬¡è°ƒç”¨
                                elif etype == "content_block_stop":
                                    if anthropic_tool_current is not None:
                                        args_text = anthropic_tool_current.get("input_json", "") or ""
                                        # å°è¯•è§£æä¸ºå¯¹è±¡ï¼›å¤±è´¥åˆ™ä¿ç•™åŸå­—ç¬¦ä¸²
                                        try:
                                            parsed_args = json.loads(args_text) if args_text else {}
                                        except Exception:
                                            parsed_args = args_text
                                        tool_call = {
                                            "id": anthropic_tool_current.get("id") or str(uuid.uuid4()),
                                            "type": "function",
                                            "function": {
                                                "name": anthropic_tool_current.get("name") or "unknown_tool",
                                                "arguments": json.dumps(parsed_args, ensure_ascii=False)
                                            }
                                        }
                                        anthropic_tool_calls.append(tool_call)
                                        anthropic_tool_current = None
                                # æ¶ˆæ¯å¢é‡ï¼ˆå¯å« stop_reasonï¼‰
                                elif etype == "message_delta":
                                    delta = evt.get("delta", {})
                                    sr = delta.get("stop_reason")
                                    if sr:
                                        anthropic_stop_reason = sr
                                # å…¶ä½™äº‹ä»¶å¿½ç•¥
                            except Exception:
                                # å•äº‹ä»¶è§£æå¤±è´¥ä¸å½±å“é€ä¼ 
                                pass
                        # åŒæ—¶å¤ç”¨ç°æœ‰è§£æä»¥å…¼å®¹åªæ–‡æœ¬çš„æƒ…å†µ
                        complete_response, response_id, _ = self._parse_anthropic_stream_chunk(
                            line_str, complete_response, response_id
                        )
                    elif auth_type == "google":
                        chunk_reasoning = ""
                        complete_response, response_id, chunk_reasoning = await self._parse_google_stream_chunk(
                            line_str, complete_response, response_id
                        )
                        if chunk_reasoning:
                            complete_reasoning += chunk_reasoning
                    else:
                        chunk_reasoning = ""
                        complete_response, response_id, chunk_reasoning = self._parse_openai_stream_chunk(
                            line_str, complete_response, response_id
                        )
                        if chunk_reasoning:
                            complete_reasoning += chunk_reasoning
        
        except Exception as e:
            await self.async_logger.error(f"æµå¼å“åº”å¤„ç†é”™è¯¯: {e}")
            await self.async_logger.error(f"é”™è¯¯è¯¦æƒ…: {traceback.format_exc()}")
        
        finally:
            # ä¿å­˜å¯¹è¯ - å¤„ç†ä¸åŒAPIæ ¼å¼çš„æ¶ˆæ¯è½¬æ¢
            # ä¿®æ”¹ï¼šå½“å­˜åœ¨å·¥å…·è°ƒç”¨æ—¶ï¼ˆAnthropic stop_reason=tool_useï¼‰ï¼Œå³ä½¿æ²¡æœ‰å¯è§æ–‡æœ¬ä¹Ÿä¿å­˜
            save_due_to_tool = (auth_type == "anthropic" and len(anthropic_tool_calls) > 0)
            # å…œåº•ï¼šè‹¥ä¸Šæ¸¸æœªæä¾›response_idï¼Œç”Ÿæˆä¸€ä¸ªUUIDä»¥ç¡®ä¿å¯å…¥åº“
            if not response_id:
                response_id = str(uuid.uuid4())
            # å§‹ç»ˆå…¥é˜Ÿä¿å­˜ï¼ˆå³ä¾¿å¯è§æ–‡æœ¬ä¸ºç©ºï¼‰ï¼Œç¡®ä¿å®¡è®¡ä¸æ’æŸ¥å®Œæ•´
            if True:
                # å®¡è®¡ï¼šä»…å·¥å…·è°ƒç”¨ä¹Ÿä¿å­˜æ—¶æ‰“å° INFO
                if save_due_to_tool and not complete_response:
                    tool_names = ", ".join([tc.get("function", {}).get("name", "unknown_tool") for tc in anthropic_tool_calls]) or "unknown_tool"
                    # é»˜è®¤é™ä¸º DEBUGï¼Œå¦‚éœ€ INFO çº§åˆ«å®¡è®¡ï¼Œè®¾ç½®ç¯å¢ƒå˜é‡ PROXY_AUDIT_TOOL_SAVE
                    if os.getenv("PROXY_AUDIT_TOOL_SAVE"):
                        await self.async_logger.info(f"ğŸ“Œ ä¿å­˜äºå·¥å…·é˜¶æ®µï¼ˆfunction_call-onlyï¼‰ï¼Œæ•°é‡={len(anthropic_tool_calls)}ï¼Œå·¥å…·={tool_names}")
                    else:
                        await self.async_logger.debug(f"ğŸ“Œ ä¿å­˜äºå·¥å…·é˜¶æ®µï¼ˆfunction_call-onlyï¼‰ï¼Œæ•°é‡={len(anthropic_tool_calls)}ï¼Œå·¥å…·={tool_names}")
                # å¤„ç†ä¸åŒAPIæ ¼å¼çš„æ¶ˆæ¯è½¬æ¢
                # ç»Ÿä¸€æŠ½å–å½’æ¡£æ¶ˆæ¯ï¼Œå…¼å®¹ Google contents ä¸ OpenAI messages
                messages = self._extract_messages_for_archive(auth_type, request_data)
                
                # å­˜æ¡£ï¼š
                # - OpenAI/Googleï¼šæœ‰ç»“æ„åŒ–æ€è€ƒæ—¶é™„åŠ <think>
                # - Anthropicï¼šè‹¥æœ‰å·¥å…·è°ƒç”¨ï¼Œè¿½åŠ æ ‡è®°ä»¥ä¾¿ utils.format_to_sharegpt æŠ½å–ä¸º function_call
                if auth_type in ("openai", "google") and complete_reasoning:
                    formatted_response = f"<think>\n{complete_reasoning}\n</think>\n\n{complete_response}"
                else:
                    formatted_response = complete_response
                if auth_type == "anthropic" and len(anthropic_tool_calls) > 0:
                    try:
                        marker = json.dumps(anthropic_tool_calls, ensure_ascii=False)
                    except Exception:
                        marker = "[]"
                    append_text = f"[ANTHROPIC_TOOL_CALLS: {marker}]"
                    if save_due_to_tool and not complete_response:
                        # fc-onlyï¼šä¸å†™ä»»ä½• assistant æ–‡æœ¬ï¼›ç›´æ¥æŠŠå·¥å…·è°ƒç”¨è½¬ä¸º function_call æ¶ˆæ¯ï¼›response ç•™ç©º
                        if not isinstance(messages, list):
                            messages = []
                        for tc in anthropic_tool_calls:
                            fn = tc.get("function", {}) if isinstance(tc, dict) else {}
                            name = fn.get("name", "unknown_tool")
                            args_val = fn.get("arguments", "{}")
                            try:
                                args_obj = json.loads(args_val) if isinstance(args_val, str) else args_val
                            except Exception:
                                args_obj = args_val
                            messages.append({
                                "role": "function_call",
                                "content": json.dumps({"name": name, "arguments": args_obj}, ensure_ascii=False)
                            })
                        formatted_response = ""  # ç¡®ä¿æ— å¯è§æ–‡æœ¬
                    else:
                        # é fc-onlyï¼šä¿ç•™åŸæœ‰è¡Œä¸ºï¼Œå°†æ ‡è®°é™„åŠ åœ¨å¯è§æ–‡æœ¬æœ«å°¾
                        formatted_response = (formatted_response or "") + "\n" + append_text
                
                # è°ƒè¯•ï¼šæ‰“å°æœ€ç»ˆä¿å­˜çš„å†…å®¹
                await self.async_logger.debug(f"ğŸ” è°ƒè¯• - æµå¼å“åº”æœ€ç»ˆå†…å®¹é•¿åº¦: {len(formatted_response)}")
                await self.async_logger.debug(f"ğŸ” è°ƒè¯• - æµå¼å“åº”å‰100å­—ç¬¦: {formatted_response[:100]}...")
                
                await self._queue_conversation(response_id, model, {
                    'request': request_data,
                    'response': formatted_response,
                    'reasoning': complete_reasoning,
                    'messages': messages
                })
        
        return response
    
    async def _handle_non_stream_response(self, resp: aiohttp.ClientResponse,
                                        auth_type: str, model: str, request_data: Dict[str, Any]) -> web.Response:
        """å¤„ç†éæµå¼å“åº”"""
        response_text = await resp.text()
        
        # è®°å½•ä¸Šæ¸¸å“åº”çŠ¶æ€
        if resp.status >= 400:
            await self.async_logger.warning(
                f"âš ï¸ ä¸Šæ¸¸æœåŠ¡å™¨è¿”å›é”™è¯¯: {resp.status} - {response_text[:200]}..."
            )
        
        try:
            response_json = json.loads(response_text)
            
            # è§£æå“åº”å†…å®¹
            complete_response = ""
            reasoning = ""
            
            if auth_type == "anthropic":
                complete_response = self._parse_anthropic_final_response(response_json)
            elif auth_type == "google":
                complete_response, reasoning = await self._parse_google_final_response(response_json)
            else:
                complete_response = self._parse_openai_final_response(response_json)
            
            # ä¿å­˜å¯¹è¯
            response_id = response_json.get('id', str(uuid.uuid4()))
            if complete_response:
                # ä¸åšæ€è€ƒæŠ½å–ï¼Œç›´æ¥ä¿å­˜åŸæ–‡
                # å¤„ç†ä¸åŒAPIæ ¼å¼çš„æ¶ˆæ¯è½¬æ¢
                # ç»Ÿä¸€æŠ½å–å½’æ¡£æ¶ˆæ¯ï¼Œå…¼å®¹ Google contents ä¸ OpenAI messages
                messages = self._extract_messages_for_archive(auth_type, request_data)
                
                # è°ƒè¯•ï¼šæ‰“å°è½¬æ¢åçš„æ¶ˆæ¯
                await self.async_logger.debug(f"ğŸ” è°ƒè¯• - è½¬æ¢åçš„æ¶ˆæ¯æ ¼å¼: {json.dumps(messages, ensure_ascii=False, indent=2)}")
                
                # å¯¹éæµå¼ï¼šä»…åœ¨ OpenAI ä¸”å­˜åœ¨ç»“æ„åŒ– reasoning_content æ—¶ï¼ŒæŠŠæ€è€ƒå¹¶å…¥ response
                combined_response = (
                    f"<think>\n{reasoning}\n</think>\n\n{complete_response}"
                    if (auth_type in ["openai", "google"] and reasoning) else complete_response
                )
                
                # è°ƒè¯•ï¼šæ‰“å°ä¿å­˜çš„å¯¹è¯æ•°æ®
                conversation_to_save = {
                    'request': request_data,
                    'response': combined_response,
                    'reasoning': reasoning,
                    'messages': messages
                }
                await self.async_logger.debug(f"ğŸ” è°ƒè¯• - å‡†å¤‡ä¿å­˜çš„å¯¹è¯æ•°æ®: {json.dumps(conversation_to_save, ensure_ascii=False, indent=2)}")
                
                # ç¡®ä¿ä¼ é€’å®Œæ•´çš„è¯·æ±‚æ¶ˆæ¯
                await self._queue_conversation(response_id, model, conversation_to_save)
        
        except Exception as e:
            await self.async_logger.error(f"è§£æå“åº”æ—¶å‘ç”Ÿé”™è¯¯: {e}")
        
        return web.Response(
            status=resp.status,
            text=response_text,
            headers={'Content-Type': 'application/json'}
        )
    
    def _parse_openai_stream_chunk(self, line_str: str, complete_response: str, response_id: Optional[str]):
        """è§£æOpenAIæµå¼å“åº”å—"""
        complete_reasoning = ""
        
        if line_str.startswith("data: "):
            if line_str.strip() == "data: [DONE]":
                return complete_response, response_id, complete_reasoning
            
            try:
                json_data = line_str[6:].strip()
                if json_data:
                    json_chunk = json.loads(json_data)
                    if "id" in json_chunk and not response_id:
                        response_id = json_chunk["id"]
                    if "choices" in json_chunk and json_chunk["choices"]:
                        delta = json_chunk["choices"][0].get("delta", {})
                        rc = delta.get("reasoning_content")
                        # å…¼å®¹å¤šç§ç»“æ„çš„ reasoning_contentï¼Œä»…ç”¨äºå­˜æ¡£ç´¯åŠ 
                        if rc is not None:
                            try:
                                if isinstance(rc, str):
                                    complete_reasoning += rc
                                elif isinstance(rc, dict):
                                    # å¸¸è§å­—æ®µå°è¯•å±•å¼€
                                    for k in ["text", "content", "message"]:
                                        v = rc.get(k)
                                        if isinstance(v, str):
                                            complete_reasoning += v
                                        elif isinstance(v, list):
                                            complete_reasoning += "".join(
                                                x.get("text", "") if isinstance(x, dict) else str(x) for x in v
                                            )
                                    # parts ç»“æ„
                                    parts = rc.get("parts")
                                    if isinstance(parts, list):
                                        complete_reasoning += "".join(
                                            x.get("text", "") if isinstance(x, dict) else str(x) for x in parts
                                        )
                                elif isinstance(rc, list):
                                    complete_reasoning += "".join(
                                        x.get("text", "") if isinstance(x, dict) else str(x) for x in rc
                                    )
                                else:
                                    # å…œåº•åºåˆ—åŒ–
                                    complete_reasoning += str(rc)
                            except Exception:
                                pass
                        content = delta.get("content")
                        if content is not None:
                            complete_response += content
            except json.JSONDecodeError:
                pass
            except Exception:
                pass
        
        return complete_response, response_id, complete_reasoning
    
    def _parse_anthropic_stream_chunk(self, line_str: str, complete_response: str, response_id: Optional[str]):
        """è§£æAnthropicæµå¼å“åº”å—"""
        if line_str.startswith("data: "):
            if line_str.strip() == "data: [DONE]":
                return complete_response, response_id, ""
            
            try:
                json_chunk = json.loads(line_str[6:])
                
                if json_chunk.get("type") == "message_start" and "message" in json_chunk:
                    message = json_chunk["message"]
                    if "id" in message and not response_id:
                        response_id = message["id"]
                
                elif json_chunk.get("type") == "content_block_delta":
                    delta = json_chunk.get("delta", {})
                    if delta.get("type") == "text_delta":
                        text = delta.get("text", "")
                        complete_response += text
                        
            except json.JSONDecodeError:
                pass
        
        return complete_response, response_id, ""
    
    def _parse_openai_final_response(self, response_json: Dict[str, Any]) -> str:
        """è§£æOpenAIæœ€ç»ˆå“åº”å†…å®¹"""
        if "choices" in response_json and response_json["choices"]:
            choice = response_json["choices"][0]
            if isinstance(choice, dict) and "message" in choice and isinstance(choice["message"], dict):
                rc = choice["message"].get("reasoning_content", "")
                # å…¼å®¹å¯¹è±¡/æ•°ç»„å½¢å¼çš„ reasoning_content
                if not isinstance(rc, str) and rc:
                    try:
                        if isinstance(rc, dict):
                            buf = []
                            for k in ["text", "content", "message"]:
                                v = rc.get(k)
                                if isinstance(v, str):
                                    buf.append(v)
                                elif isinstance(v, list):
                                    buf.extend(x.get("text", "") if isinstance(x, dict) else str(x) for x in v)
                            parts = rc.get("parts")
                            if isinstance(parts, list):
                                buf.extend(x.get("text", "") if isinstance(x, dict) else str(x) for x in parts)
                            rc = "".join(buf).strip()
                        elif isinstance(rc, list):
                            rc = "".join(x.get("text", "") if isinstance(x, dict) else str(x) for x in rc).strip()
                        else:
                            rc = str(rc)
                    except Exception:
                        rc = ""
                reasoning_content = rc if isinstance(rc, str) else ""
                response_content = choice["message"].get("content", "")
                return f"<think>\n{reasoning_content}\n</think>\n\n{response_content}" if reasoning_content else response_content
        return ""
    
    async def _parse_google_final_response(self, response_json: Dict[str, Any]) -> tuple[str, str]:
        """è§£æGoogle APIæœ€ç»ˆå“åº”å†…å®¹ï¼Œè¿”å›(å“åº”å†…å®¹, æ€è€ƒè¿‡ç¨‹)"""
        response_text = ""
        reasoning = ""
        
        # è°ƒè¯•ï¼šæ‰“å°å®Œæ•´å“åº”ç»“æ„
        import json
        await self.async_logger.debug(f"ğŸ” è°ƒè¯• - Google APIå®Œæ•´å“åº”: {json.dumps(response_json, ensure_ascii=False, indent=2)}")
        
        # æ£€æŸ¥æ˜¯å¦æœ‰é”™è¯¯çŠ¶æ€
        finish_reason = None
        if "candidates" in response_json and response_json["candidates"]:
            candidate = response_json["candidates"][0]
            await self.async_logger.debug(f"ğŸ” è°ƒè¯• - candidateç»“æ„: {json.dumps(candidate, ensure_ascii=False, indent=2)}")
            
            # è·å–finishReason
            finish_reason = candidate.get("finishReason")
            await self.async_logger.debug(f"ğŸ” è°ƒè¯• - finishReason: {finish_reason}")
            
            if finish_reason and finish_reason != "STOP":
                # å¤„ç†é”™è¯¯çŠ¶æ€
                error_message = f"APIé”™è¯¯: {finish_reason}"
                if finish_reason == "MAX_TOKENS":
                    error_message = "è¾¾åˆ°æœ€å¤§tokené™åˆ¶ï¼Œè¯·å‡å°‘è¾“å…¥å†…å®¹æˆ–è°ƒæ•´maxOutputTokenså‚æ•°"
                elif finish_reason == "SAFETY":
                    error_message = "å†…å®¹è¢«å®‰å…¨è¿‡æ»¤å™¨é˜»æ­¢"
                elif finish_reason == "RECITATION":
                    error_message = "æ£€æµ‹åˆ°å†…å®¹é‡å¤"
                
                response_text = error_message
                await self.async_logger.warning(f"âš ï¸ Google APIè¿”å›é”™è¯¯çŠ¶æ€: {finish_reason}")
                return response_text, reasoning
            
            if isinstance(candidate, dict) and "content" in candidate:
                content = candidate["content"]
                await self.async_logger.debug(f"ğŸ” è°ƒè¯• - contentç»“æ„: {json.dumps(content, ensure_ascii=False, indent=2)}")
                
                # æ£€æŸ¥contentæ˜¯å¦æœ‰partså­—æ®µ
                if isinstance(content, dict) and "parts" in content:
                    parts = content["parts"]
                    if isinstance(parts, list) and parts:
                        # åˆ†åˆ«å¤„ç†æ€è€ƒè¿‡ç¨‹å’Œå“åº”å†…å®¹
                        text_parts = []
                        thought_parts = []
                        
                        for part in parts:
                            if isinstance(part, dict):
                                is_thought_part = False
                                # ä¼˜å…ˆè§£æç»“æ„åŒ–æ€è€ƒï¼špart.thinking.thought
                                if "thinking" in part and isinstance(part.get("thinking"), dict):
                                    t = part["thinking"].get("thought")
                                    if isinstance(t, str) and t:
                                        thought_parts.append(t)
                                        is_thought_part = True
                                # å…¼å®¹æ—§ç»“æ„ï¼špart.thought == True ä¸” text å±äºæ€è€ƒ
                                elif "thought" in part and isinstance(part.get("thought"), bool) and part.get("thought") is True:
                                    t = part.get("text", "")
                                    if isinstance(t, str) and t:
                                        thought_parts.append(t)
                                        is_thought_part = True
                                # æ™®é€šæ–‡æœ¬å†…å®¹ï¼ˆé¢å‘ç”¨æˆ·å¯è§çš„å›ç­”ï¼‰ï¼Œä»…åœ¨éæ€è€ƒç‰‡æ®µæ—¶çº³å…¥
                                if (not is_thought_part) and "text" in part and isinstance(part.get("text"), str):
                                    text_parts.append(part["text"])
                        
                        # åˆå¹¶å“åº”å†…å®¹
                        response_text = "\n".join(text_parts)
                        
                        # åˆå¹¶æ€è€ƒè¿‡ç¨‹ï¼ˆä»…ä¾èµ–ç»“æ„åŒ–å­—æ®µï¼‰
                        if thought_parts:
                            reasoning = "\n".join(thought_parts).strip()
                
                # å¦‚æœcontentæ²¡æœ‰partså­—æ®µä½†æœ‰å…¶ä»–å­—æ®µï¼Œæ£€æŸ¥æ˜¯å¦ç›´æ¥åŒ…å«æ–‡æœ¬
                elif isinstance(content, dict):
                    # æ£€æŸ¥æ˜¯å¦æœ‰ç›´æ¥çš„textå­—æ®µ
                    if "text" in content:
                        response_text = content["text"]
                    # æ£€æŸ¥æ˜¯å¦æœ‰thoughtå­—æ®µ
                    if "thought" in content:
                        reasoning = content["thought"]
                    
                    # å¦‚æœcontentåªæœ‰roleå­—æ®µï¼Œå¯èƒ½å“åº”å†…å®¹ä¸ºç©º
                    if not response_text and "role" in content:
                        await self.async_logger.debug(f"ğŸ” è°ƒè¯• - contentåªæœ‰roleå­—æ®µï¼Œå“åº”å†…å®¹ä¸ºç©º")
        
        # è°ƒè¯•ï¼šæ‰“å°æå–ç»“æœ
        await self.async_logger.debug(f"ğŸ” è°ƒè¯• - æå–çš„å“åº”å†…å®¹é•¿åº¦: {len(response_text)}")
        await self.async_logger.debug(f"ğŸ” è°ƒè¯• - æå–çš„æ€è€ƒè¿‡ç¨‹é•¿åº¦: {len(reasoning)}")
        
        return response_text, reasoning
    
    async def _parse_google_stream_chunk(self, line_str: str, complete_response: str, response_id: Optional[str]):
        """è§£æGoogle APIæµå¼å“åº”å—ï¼›å…¼å®¹ OpenAI é£æ ¼çš„ choices.delta"""
        complete_reasoning = ""
        await self.async_logger.debug(f"ğŸ” è°ƒè¯• - Googleæµå¼åŸå§‹æ•°æ®: {repr(line_str[:100])}")
        
        # ç»Ÿä¸€æå– JSON è½½è·
        payload = line_str.strip()
        if payload.startswith("data: "):
            if payload.strip() == "data: [DONE]":
                return complete_response, response_id, complete_reasoning
            payload = payload[6:].strip()
        if not payload:
            return complete_response, response_id, complete_reasoning
        
        try:
            if not (payload.startswith("{") and payload.endswith("}")):
                # éå®Œæ•´ JSON çš„ç®€æ˜“æå–ï¼ˆGoogle ç‰‡æ®µï¼‰
                if '"text":' in payload and '"thought": true' not in payload and '"thinking"' not in payload:
                    import re as _re
                    m = _re.search(r'"text":\s*"([^"]*)"', payload)
                    if m:
                        complete_response += m.group(1)
                if '"responseId":' in payload and not response_id:
                    import re as _re
                    m = _re.search(r'"responseId":\s*"([^"]*)"', payload)
                    if m:
                        response_id = m.group(1)
                return complete_response, response_id, complete_reasoning
            
            # è§£æå®Œæ•´ JSON
            obj = json.loads(payload)
            # å…¼å®¹ OpenAI é£æ ¼ chunkï¼šchoices.delta
            if isinstance(obj, dict) and "choices" in obj and obj.get("choices"):
                ch0 = obj["choices"][0]
                if isinstance(ch0, dict):
                    delta = ch0.get("delta") or {}
                    if "id" in obj and not response_id:
                        response_id = obj["id"]
                    rc = delta.get("reasoning_content")
                    if rc is not None:
                        try:
                            if isinstance(rc, str):
                                complete_reasoning += rc
                            elif isinstance(rc, dict):
                                for k in ("text", "content", "message"):
                                    v = rc.get(k)
                                    if isinstance(v, str):
                                        complete_reasoning += v
                                    elif isinstance(v, list):
                                        complete_reasoning += "".join(x.get("text", "") if isinstance(x, dict) else str(x) for x in v)
                                parts = rc.get("parts")
                                if isinstance(parts, list):
                                    complete_reasoning += "".join(x.get("text", "") if isinstance(x, dict) else str(x) for x in parts)
                            elif isinstance(rc, list):
                                complete_reasoning += "".join(x.get("text", "") if isinstance(x, dict) else str(x) for x in rc)
                            else:
                                complete_reasoning += str(rc)
                        except Exception:
                            pass
                    content = delta.get("content")
                    if isinstance(content, str):
                        complete_response += content
                return complete_response, response_id, complete_reasoning
            
            # Google candidates è§£æ
            if "responseId" in obj and not response_id:
                response_id = obj["responseId"]
            if "candidates" in obj and obj.get("candidates"):
                cand = obj["candidates"][0]
                cont = cand.get("content", {})
                parts = cont.get("parts", [])
                if isinstance(parts, list):
                    for part in parts:
                        if not isinstance(part, dict):
                            continue
                        # æ€è€ƒ
                        if "thinking" in part and isinstance(part.get("thinking"), dict):
                            t = part["thinking"].get("thought")
                            if isinstance(t, str) and t:
                                complete_reasoning += t
                        elif part.get("thought") is True:
                            t = part.get("text")
                            if isinstance(t, str) and t:
                                complete_reasoning += t
                        # å¯è§æ–‡æœ¬
                        elif "text" in part and isinstance(part.get("text"), str):
                            complete_response += part["text"]
        except Exception as e:
            await self.async_logger.error(f"Googleæµå¼è§£æé”™è¯¯: {e}")
            await self.async_logger.error(f"é”™è¯¯è¯¦æƒ…: {traceback.format_exc()}")
        
        return complete_response, response_id, complete_reasoning
    
    def _parse_anthropic_final_response(self, response_json: Dict[str, Any]) -> str:
        """è§£æAnthropicæœ€ç»ˆå“åº”å†…å®¹"""
        content_list = response_json.get("content", [])
        response_content = ""
        
        if isinstance(content_list, list) and content_list:
            for content_item in content_list:
                if isinstance(content_item, dict):
                    if content_item.get("type") == "text":
                        response_content += content_item.get("text", "")
        
        return response_content
    

    

    
    async def _queue_conversation(self, id: str, model: str, conversation: dict):
        """å°†å¯¹è¯åŠ å…¥é˜Ÿåˆ—ç­‰å¾…æ‰¹é‡ä¿å­˜"""
        try:
            conversation_data = {
                'id': id,
                'model': model,
                'conversation': conversation,
                'timestamp': time.time()
            }
            await self.conversation_queue.put(conversation_data)
        except Exception as e:
            await self.async_logger.error(f"åŠ å…¥å¯¹è¯é˜Ÿåˆ—å¤±è´¥: {e}")
    
    async def _batch_save_conversations(self):
        """æ‰¹é‡ä¿å­˜å¯¹è¯"""
        batch = []
        last_save_time = time.time()
        
        while True:
            try:
                # ç­‰å¾…æ–°çš„å¯¹è¯æ•°æ®æˆ–è¶…æ—¶
                try:
                    conversation_data = await asyncio.wait_for(
                        self.conversation_queue.get(), 
                        timeout=self.batch_timeout
                    )
                    batch.append(conversation_data)
                except asyncio.TimeoutError:
                    pass
                
                current_time = time.time()
                
                # æ£€æŸ¥æ˜¯å¦éœ€è¦ä¿å­˜æ‰¹æ¬¡
                should_save = (
                    len(batch) >= self.batch_size or
                    (batch and current_time - last_save_time >= self.batch_timeout)
                )
                
                if should_save and batch:
                    await self._save_batch(batch)
                    batch = []
                    last_save_time = current_time
                    
            except Exception as e:
                await self.async_logger.error(f"æ‰¹é‡ä¿å­˜å¯¹è¯æ—¶å‘ç”Ÿé”™è¯¯: {e}")
                await asyncio.sleep(1)
    
    async def _save_batch(self, batch):
        """ä¿å­˜ä¸€æ‰¹å¯¹è¯ï¼ˆå¤ç”¨å•ä¸ª DB è¿æ¥æå‡æ€§èƒ½ï¼‰"""
        db_conn = None
        try:
            db_conn = await get_db_connection()
            for conversation_data in batch:
                # æ£€æŸ¥æ•°æ®ç»“æ„
                if not isinstance(conversation_data, dict):
                    await self.async_logger.error(f"æ— æ•ˆçš„å¯¹è¯æ•°æ®ç±»å‹: {type(conversation_data)}")
                    continue
                
                if 'conversation' not in conversation_data:
                    await self.async_logger.error(f"å¯¹è¯æ•°æ®ç¼ºå°‘conversationå­—æ®µ: {conversation_data}")
                    continue
                
                conversation = conversation_data['conversation']
                if not isinstance(conversation, dict):
                    await self.async_logger.error(f"conversationå­—æ®µç±»å‹é”™è¯¯: {type(conversation)}")
                    continue
                
                # æ ¼å¼åŒ–ä¸ºShareGPTæ ¼å¼
                # ä¼˜å…ˆä½¿ç”¨conversationä¸­çš„messagesï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨requestä¸­çš„messages
                messages = conversation.get('messages', conversation.get('request', {}).get('messages', []))
                # å…¥åº“è½»é‡çº æ­£ï¼šä¿®å¤â€œè¿ç»­ä¸¤ä¸ª user ä¸”ç¬¬äºŒæ¡åƒ AI å›ç­”â€
                norm_changed = False
                try:
                    messages, norm_changed = normalize_roles(messages)
                except Exception:
                    norm_changed = False
                if norm_changed:
                    # å®¡è®¡æ ‡è®° + ä¿ç•™åŸå§‹è¯·æ±‚
                    try:
                        flags = conversation.setdefault('flags', [])
                        if 'normalized_roles' not in flags:
                            flags.append('normalized_roles')
                        conversation.setdefault('request_raw', conversation.get('request', {}))
                    except Exception:
                        pass
                # è°ƒè¯•ï¼šæ‰“å°æ ¼å¼åŒ–å‰çš„æ•°æ®
                await self.async_logger.debug(f"ğŸ” è°ƒè¯• - æ ¼å¼åŒ–å‰çš„æ¶ˆæ¯: {json.dumps(messages, ensure_ascii=False, indent=2)}")
                await self.async_logger.debug(f"ğŸ” è°ƒè¯• - å“åº”å†…å®¹: {conversation.get('response', '')}")
                
                sharegpt_data = format_to_sharegpt(
                    conversation_data.get('model', 'unknown'),
                    messages,
                    conversation.get('response', ''),
                    conversation.get('request', {})
                )
                
                # è°ƒè¯•ï¼šæ‰“å°æ ¼å¼åŒ–åçš„æ•°æ®
                await self.async_logger.debug(f"ğŸ” è°ƒè¯• - æ ¼å¼åŒ–åçš„ShareGPTæ•°æ®: {json.dumps(sharegpt_data, ensure_ascii=False, indent=2)}")
                
                # ä¿å­˜åˆ°æ•°æ®åº“ï¼ˆå¤ç”¨è¿æ¥ï¼‰
                await save_conversation_async(
                    db_conn,
                    conversation_data.get('id', str(uuid.uuid4())),
                    conversation_data.get('model', 'unknown'),
                    sharegpt_data
                )
            
            await self.async_logger.info(f"âœ… æˆåŠŸä¿å­˜ {len(batch)} æ¡å¯¹è¯")
            
        except Exception as e:
            await self.async_logger.error(f"ä¿å­˜å¯¹è¯æ‰¹æ¬¡å¤±è´¥: {e}\n{traceback.format_exc()}")
        finally:
            if db_conn is not None:
                try:
                    await db_conn.close()
                except Exception:
                    pass
    
    async def handle_health_check(self, request: web.Request) -> web.Response:
        """å¥åº·æ£€æŸ¥ç«¯ç‚¹"""
        return web.Response(
            status=200,
            text=json.dumps({
                "status": "healthy",
                "service": "dynamic-proxy",
                "timestamp": time.time()
            }),
            headers={'Content-Type': 'application/json'}
        )

if __name__ == "__main__":
    args = parse_args()
    proxy = DynamicProxyEndpoint(port=args.port)
    try:
        web.run_app(proxy.app, host="0.0.0.0", port=args.port)
    except Exception as e:
        logger.error(f"å¯åŠ¨æœåŠ¡å™¨æ—¶å‘ç”Ÿè‡´å‘½é”™è¯¯: {e}", exc_info=True)
    finally:
        logger.info("æœåŠ¡å™¨å·²å…³é—­")